<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>wuyuchun</title>
    <description>欢迎来到我的个人站~</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sat, 23 May 2020 14:30:14 +0800</pubDate>
    <lastBuildDate>Sat, 23 May 2020 14:30:14 +0800</lastBuildDate>
    <generator>Jekyll v4.0.0</generator>
    
      <item>
        <title>Profiler_cuda</title>
        <description>
&lt;hr /&gt;
&lt;p&gt;layout: post&lt;/p&gt;

&lt;p&gt;title:  “profiler_cuda”&lt;/p&gt;

&lt;p&gt;date:   2020-05-16 14:29&lt;/p&gt;

&lt;p&gt;excerpt:&lt;/p&gt;

&lt;p&gt;tag:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;h2 id=&quot;gpu&quot;&gt;GPU&lt;/h2&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[TOC]&lt;/p&gt;

&lt;h1 id=&quot;简介&quot;&gt;简介&lt;/h1&gt;

&lt;p&gt;主要用于针对于cuda函数进行性能测量&lt;/p&gt;

&lt;p&gt;本文档介绍了NVIDIA的剖析工具，使您能够了解并优化您的CUDA、OpenACC或OpenMP应用程序的性能。Visual Profiler是一个图形化的剖析工具，它可以显示应用程序的CPU和GPU活动的时间轴，其中包括一个自动分析引擎，可识别出优化机会。nvprof profiling工具可以让你从命令行收集和查看分析数据。&lt;/p&gt;

&lt;p&gt;建议使用下一代工具NVIDIA Nsight Compute进行GPU分析，以及NVIDIA Nsight Systems进行GPU和CPU采样和追踪。&lt;/p&gt;

&lt;p&gt;NVIDIA Nsight Compute是一款针对CUDA应用程序的交互式内核分析器。它通过一个用户界面和命令行工具提供详细的性能指标和API调试。此外，其基线功能允许用户在工具内比较结果。Nsight Compute提供了一个可定制的、数据驱动的用户界面和&lt;strong&gt;指标收集&lt;/strong&gt;，并可通过&lt;strong&gt;分析脚本&lt;/strong&gt;进行后处理结果的扩展。&lt;/p&gt;

&lt;p&gt;NVIDIA Nsight Systems是一款全系统的性能分析工具，其设计目的是将应用的算法可视化，帮助您识别出最大的优化机会，并在任何数量或大小的CPU和GPU上进行有效的调整，从大型服务器到最小的SoC。&lt;/p&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;这两者的区别是什么呢？&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;术语&quot;&gt;术语&lt;/h1&gt;

&lt;p&gt;event是指设备上的&lt;strong&gt;可计数&lt;/strong&gt;的活动、动作以及发生。它对应于内核执行过程中收集的单个硬件&lt;strong&gt;计数器值&lt;/strong&gt;。要查看特定NVIDIA GPU上所有可用事件的列表，请键入 nvprof –query-events。&lt;/p&gt;

&lt;p&gt;metric是一个应用程序的特性，它是&lt;strong&gt;由一个或多个事件值计算&lt;/strong&gt;出来的。要查看一个特定的NVIDIA GPU上所有可用的指标列表，请键入 nvprof –query-metrics。你也可以参考度量指标参考。&lt;/p&gt;

&lt;h1 id=&quot;性能报告分析&quot;&gt;性能报告分析&lt;/h1&gt;

&lt;h2 id=&quot;聚焦特定的部分上&quot;&gt;聚焦特定的部分上&lt;/h2&gt;

&lt;p&gt;默认情况下，剖析工具会在整个应用程序的运行过程中收集配置文件数据。但是，正如下面所解释的，通常只想对应用程序中包含部分或全部性能关键代码的区域进行剖析。将剖面分析限制在性能关键区域，可以减少工具必须处理的剖面数据量，并将注意力集中在优化能带来最大性能提升的代码上。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;当应用程序的每个阶段的性能都可以独立于其他阶段进行优化时，你要对每个阶段分别进行剖析，以便集中优化工作。&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;n&quot;&gt;cudaProfilerStart&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
 &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;cudaProfilerStop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;注意事项:&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;When using the start and stop functions, you also need to instruct the profiling tool to disable profiling at the start of the application. For nvprof you do this with the –profile-from-start off flag. For the Visual Profiler you use the Start execution with profiling enabled checkbox in the Settings View.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;标记cpu的活动&quot;&gt;标记CPU的活动&lt;/h2&gt;

&lt;p&gt;要了解应用程序的CPU线程在CUDA函数调用之外的工作，可以使用NVIDIA Tools Extension API (NVTX)。&lt;/p&gt;

&lt;h2 id=&quot;刷新profile-data&quot;&gt;刷新Profile Data&lt;/h2&gt;

&lt;p&gt;为了减少剖析开销，剖析工具收集和记录剖析信息到内部缓冲区。然后这些缓冲区被异步冲洗到磁盘上，并以低速 优先级，以避免扰乱应用行为。为了避免丢失配置文件信息 还没有被冲洗，被剖析的应用程序应确保在 退出，所有的GPU工作都已完成（使用CUDA同步调用），然后 调用 cudaProfilerStop() 或 cuProfilerStop()。这样做会迫使缓冲profile 相应的上下文信息。&lt;/p&gt;

&lt;p&gt;注意：要是没有调用stop的函数，会导致丢失大量profile 数据。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;还有另一种办法：使用 nvprof 选项 –timeout 或在 Visual Profiler 中设置 “Execution timeout”。分析器将在超时前强制进行数据刷新。&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&quot;visual-profiler的使用&quot;&gt;Visual Profiler的使用&lt;/h1&gt;

&lt;p&gt;NVIDIA Visual Profiler 可让您将应用程序的性能可视化并进行优化。&lt;/p&gt;

&lt;p&gt;Visual Profiler 的独立版本，即 &lt;strong&gt;nvvp&lt;/strong&gt;，包含在所有支持的操作系统的 CUDA 工具包中。&lt;/p&gt;

&lt;h2 id=&quot;session&quot;&gt;session&lt;/h2&gt;

&lt;p&gt;会话包含与您的应用程序关联的设置，数据和结果。&lt;/p&gt;

&lt;p&gt;session文件有两种：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;直接用visual Profiler生成的&lt;/li&gt;
  &lt;li&gt;直接用nvprof来生成&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;timeline-view时间轴&quot;&gt;timeline view(时间轴)&lt;/h3&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;如何使用时间轴&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;分析窗口&quot;&gt;分析窗口&lt;/h3&gt;

&lt;p&gt;分析视图用于控制应用程序分析并显示分析结果。 有两种分析模式：引导模式和非引导模式。 在引导模式下进行分析系统将指导您完成多个分析阶段，以帮助您了解应用程序中可能存在的性能限制因素和优化机会。 在非引导模式下，您可以手动浏览为您收集的所有分析结果应用。&lt;/p&gt;

&lt;h3 id=&quot;pc采样窗口&quot;&gt;PC采样窗口&lt;/h3&gt;

&lt;h3 id=&quot;内存分析&quot;&gt;内存分析&lt;/h3&gt;

&lt;p&gt;绿色节点表示逻辑存储空间，而蓝色表示芯片的实际硬件单元&lt;/p&gt;

&lt;h3 id=&quot;源码和汇编的分析&quot;&gt;源码和汇编的分析&lt;/h3&gt;

&lt;p&gt;注意：To be able to view the kernel source you need to compile the code using the **-lineinfo **option.&lt;/p&gt;

&lt;h3 id=&quot;gpu详细窗口&quot;&gt;GPU详细窗口&lt;/h3&gt;

&lt;h3 id=&quot;cpu窗口&quot;&gt;CPU窗口&lt;/h3&gt;

&lt;h1 id=&quot;nvprof的使用&quot;&gt;nvprof的使用&lt;/h1&gt;

&lt;p&gt;使用nvprof分析工具，您可以从命令行收集和查看分析数据。 nvprof支持在CPU和GPU上收集与CUDA相关的活动的时间表，包括&lt;strong&gt;内核执行，内存传输，内存集和CUDA API调用以及CUDA内核&lt;/strong&gt;的事件或指标。 提供了分析选项，通过命令行选项访问nvprof。 收集分析数据后，分析结果将显示在控制台中，也可以保存以供以后由nvprof或Visual Profiler查看。&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Usage: nvprof &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;options] &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;application] &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;application-arguments]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;profile模式&quot;&gt;profile模式&lt;/h2&gt;

&lt;h3 id=&quot;概要模式&quot;&gt;概要模式&lt;/h3&gt;

&lt;p&gt;摘要模式是nvprof的默认操作模式。 在此模式下，nvprof输出每个内核功能和每种CUDA内存复制/类型的单个结果行设置由应用程序执行。 对于每个内核，nvprof输出的总时间为内核或内存副本类型的所有实例以及平均值，最小值，和最长的时间。 内核时间是设备上内核执行时间。默认情况下，nvprof还会打印所有CUDA运行时/驱动程序API调用的摘要。&lt;/p&gt;

&lt;h3 id=&quot;gpu-跟踪和api模式&quot;&gt;GPU-跟踪和API模式&lt;/h3&gt;

&lt;p&gt;可以单独或一起启用GPU-Trace和API-Trace模式。 GPU跟踪模式提供了按时间顺序显示GPU上发生的所有活动的时间表。 输出中显示了每个内核执行和内存复制/设置实例。 对于每个内核或内存副本，将显示详细信息，例如内核参数，共享内存使用率和内存传输吞吐量。 内核名称后方括号中显示的数字与启动该内核的CUDA API相关。&lt;strong&gt;–print-gpu-trace&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;nvprof &lt;span class=&quot;nt&quot;&gt;--print-gpu-trace&lt;/span&gt; ./vectorAdd
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;Vector addition of 50000 elements]
&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;7522&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; NVPROF is profiling process 7522, &lt;span class=&quot;nb&quot;&gt;command&lt;/span&gt;: ./vectorAdd
Copy input data from the host memory to the CUDA device
CUDA kernel launch with 196 blocks of 256 threads
Copy output data from the CUDA device to the host memory
Test PASSED
Done
&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;7522&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; Profiling application: ./vectorAdd
&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;7522&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; Profiling result:
   Start  Duration            Grid Size      Block Size     Regs&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;    SSMem&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;    DSMem&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;      Size  Throughput  SrcMemType  DstMemType           Device   Context    Stream  Name
330.01ms  16.992us                    -               -         -         -         -  195.31KB  10.962GB/s    Pageable      Device  GeForce GTX 108         1         7  &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;CUDA memcpy HtoD]
330.05ms  16.416us                    -               -         -         -         -  195.31KB  11.347GB/s    Pageable      Device  GeForce GTX 108         1         7  &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;CUDA memcpy HtoD]
330.08ms  2.7520us            &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;196 1 1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;       &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;256 1 1&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;         8        0B        0B         -           -           -           -  GeForce GTX 108         1         7  vectorAdd&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;float const &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;, float const &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;, float&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;, int&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;111]
330.09ms  16.128us                    -               -         -         -         -  195.31KB  11.549GB/s      Device    Pageable  GeForce GTX 108         1         7  &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;CUDA memcpy DtoH]

Regs: Number of registers used per CUDA thread. This number includes registers used internally by the CUDA driver and/or tools and can be more than what the compiler shows.
SSMem: Static shared memory allocated per CUDA block.
DSMem: Dynamic shared memory allocated per CUDA block.
SrcMemType: The &lt;span class=&quot;nb&quot;&gt;type &lt;/span&gt;of &lt;span class=&quot;nb&quot;&gt;source &lt;/span&gt;memory accessed by memory operation/copy
DstMemType: The &lt;span class=&quot;nb&quot;&gt;type &lt;/span&gt;of destination memory accessed by memory operation/copy

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;事件和metric模式&quot;&gt;事件和metric模式&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;nvprof is able to collect multiple events/metrics at the same time.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nl&quot;&gt;Q:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;How&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;you&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;detailed&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;profile&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CUDA&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;When&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;profiling&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;I&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;use&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;nvprof&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kernels&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;kernelName&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;listOfMetrics&quot;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;your&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;application&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Now&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;useful&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;eligible_warps_per_cycle&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;achieved_occupancy&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sm_efficiency&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;alu_fu_utilization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dram_utilization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;inst_replay_overhead&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gst_transactions_per_request&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;l2_utilization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gst_requested_throughput&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;flop_count_dp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gld_transactions_per_request&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;global_cache_replay_overhead&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;flop_dp_efficiency&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gld_efficiency&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gld_throughput&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;l2_write_throughput&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;l2_read_throughput&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;To collect all events available on each device, use the option –events all.
To collect all metrics available on each device, use the option –metrics all.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;eventmetric-跟踪模式&quot;&gt;event/metric 跟踪模式&lt;/h3&gt;

&lt;h2 id=&quot;profiling控制&quot;&gt;profiling控制&lt;/h2&gt;

&lt;h3 id=&quot;unified-memory-profiling&quot;&gt;Unified Memory Profiling&lt;/h3&gt;

&lt;h3 id=&quot;cpu-thread-tracing&quot;&gt;CPU Thread Tracing&lt;/h3&gt;

&lt;h2 id=&quot;输出&quot;&gt;输出&lt;/h2&gt;

&lt;h3 id=&quot;重定向输出&quot;&gt;重定向输出&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;--log-file %1 ： output to stdout
--logfile &amp;lt;filename&amp;gt; : ouput to file
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;dependency-analysis&quot;&gt;Dependency Analysis&lt;/h2&gt;

&lt;h2 id=&quot;cpu采样&quot;&gt;CPU采样&lt;/h2&gt;

&lt;h1 id=&quot;远程prifiling&quot;&gt;远程prifiling&lt;/h1&gt;

&lt;p&gt;两种远程profiler的方式&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;配置nsight或visual prolifer&lt;/li&gt;
  &lt;li&gt;使用nvprof来收集数据，然后用nvvp来展示&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;visual-profier-远程profiler&quot;&gt;visual profier 远程profiler&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;To use the Visual Profiler remote profiling you must install the same version of the CUDA Toolkit on both the host and remote systems.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;远程nvprof&quot;&gt;远程nvprof&lt;/h2&gt;

&lt;h1 id=&quot;nvtx&quot;&gt;NVTX&lt;/h1&gt;

&lt;p&gt;NVIDIA Tools Extension（NVTX）是基于C的应用程序编程接口（API），用于注释应用程序中的事件，代码范围和资源。 集成了NVTX的应用程序可以使用Visual Profiler捕获和可视化这些事件和范围。 NVTX API提供两项核心服务：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;追踪CPU事件和时间范围&lt;/li&gt;
  &lt;li&gt;os的名字以及cuda的资源&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;api浏览&quot;&gt;API浏览&lt;/h2&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;这个是怎么用呢？有什么用处呢？&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;mpi-profiler&quot;&gt;MPI profiler&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://devblogs.nvidia.com/gpu-pro-tip-track-mpi-calls-nvidia-visual-profiler/&quot;&gt;博客中的例子&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;mps-profiler&quot;&gt;MPS profiler&lt;/h1&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;如何使用&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;metrics-profiler&quot;&gt;metrics profiler&lt;/h1&gt;

&lt;h2 id=&quot;3x计算力的metrics&quot;&gt;3.x计算力的metrics&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;achieved_occupancy&lt;/th&gt;
      &lt;th&gt;每个活动cycle的平均活动warp数与一个多处理器上支持的最大扭曲数之比&lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;alu_fu_utilization&lt;/td&gt;
      &lt;td&gt;执行整数和浮点算术指令的多处理器功能单元的利用率级别（范围0-10）&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;atomic_replay_overhead&lt;/td&gt;
      &lt;td&gt;由于执行的每条指令的原子和reduction bank冲突导致的平均重播次数&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;atomic_throughput&lt;/td&gt;
      &lt;td&gt;全局内存原子和reduction的吞吐量&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;atomic_transactions&lt;/td&gt;
      &lt;td&gt;全局内存原子和reduction的事务&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;atomic_transactions_per_request&lt;/td&gt;
      &lt;td&gt;每个原子和约简指令执行的全局内存原子和约简事务的平均数量&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;针对于不同的计算能力有不同的metrics&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;warp状态&quot;&gt;warp状态&lt;/h1&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li&gt;
    &lt;p&gt;指令发射状态：一条指令或一对独立的指令是由warp发出的。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;停滞：在&lt;strong&gt;PC采样视图&lt;/strong&gt;中的源级或内核级的延迟分析中使用 “Examine Stall Reasons “可以看到滞留原因的分布。&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;停滞不前的指令提取—-下一条指令还没来得及发出。
        &lt;ul&gt;
          &lt;li&gt;如果内核中的大循环已经被解压，请尝试减少它们。&lt;/li&gt;
          &lt;li&gt;如果内核中包含许多小函数的调用，尝试内联更多的小函数。用 &lt;strong&gt;inline&lt;/strong&gt; 或 &lt;strong&gt;forceinline&lt;/strong&gt; 修饰符。反之，如果内联许多函数或大型函数，请尝试__noinline__来禁用内嵌式的这些函数。&lt;/li&gt;
          &lt;li&gt;对于非常短的内核，考虑融合成一个单一的内核。&lt;/li&gt;
          &lt;li&gt;如果使用较少的线程块，考虑使用更少的线程块。线程。偶尔调用 __syncthreads()将使经线程保持同步。这可能会提高指令缓存的命中率。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;因执行依赖性而停滞 - –下一条指令正在等待一个或多个输入被前面的指令计算。&lt;/p&gt;

    &lt;p&gt;为了减少执行依赖性停顿，可以尝试增加指令级并行化（ILP）。例如，可以通过增加循环解卷或每个线程处理几个元素来实现。这可以防止线程通过每条指令的全部延迟来防止线程闲置。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;因内存依赖而停滞–下一条指令正在等待前一条内存访问完成。&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;试着提高内存凝聚力和/或读取字节的效率。(对齐等)。看源头层面的分析 “全局内存访问”。
模式 “和/或指标gld_efficiency和gst_efficiency。&lt;/li&gt;
      &lt;li&gt;尝试增加内存级并行度（MLP）：内存级并行度（MLP）的数量。每个线程飞行中的独立内存操作。循环开卷。加载向量类型，如float4，并对每个元素进行多元素处理。线程都是增加内存级并行性的方法。&lt;/li&gt;
      &lt;li&gt;考虑将经常访问的数据移到更接近SM，例如通过使用 共享内存或只读数据缓存。&lt;/li&gt;
      &lt;li&gt;考虑尽可能地重新计算数据，而不是从 设备内存。&lt;/li&gt;
      &lt;li&gt;如果本地存储器访问量大，可考虑增加每个寄存器的数量。线路，以减少溢出，即使是以占用为代价，因为当地的 内存访问只缓存在L2中，对于具有计算能力的GPU来说，内存访问只缓存在L2中。主版本=5。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;因内存节流而停滞不前 - –大量未完成的内存请求阻碍了前向进展。在具有计算能力major = 3的GPU上，内存节流表示内存重播数量较多。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;纹理停滞–纹理子系统已被充分利用或有太多的未完成请求。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;停滞不前的同步—-warp在同步指令后等待所有线程同步。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;因持续依赖内存而停滞不前&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;因管道繁忙而停滞—-因为执行下一条指令所需的功能单元忙，所以warp停滞。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;停滞的原因是未被选中–warp已经准备好了，但由于其他warp被选中发行，所以没有机会发行。这个原因一般说明内核可能优化得很好，但在某些情况下，你可以在不影响延迟隐藏的情况下降低占用率，这样做可能有助于提高缓存命中率。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;
    &lt;p&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;如何分析一个kernel函数？&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Sat, 16 May 2020 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2020/05/profiler_cuda/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/05/profiler_cuda/</guid>
        
        
      </item>
    
      <item>
        <title>cuda的编译</title>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;

&lt;h1 id=&quot;简介&quot;&gt;简介&lt;/h1&gt;

&lt;p&gt;这里主要介绍nvcc编译器的工作&lt;/p&gt;

&lt;h1 id=&quot;介绍&quot;&gt;介绍&lt;/h1&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;cuda的源文件是如何编译成可执行文件的&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;编译阶段&quot;&gt;编译阶段&lt;/h1&gt;

&lt;h2 id=&quot;nvcc阶段&quot;&gt;NVCC阶段&lt;/h2&gt;

&lt;p&gt;每当主机程序启动设备代码时，CUDA运行时系统就会对嵌入式的fatbinary进行检查，以获得适合当前GPU的fatbinary映像。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2020-05-15-09-32-19-nvcc-build.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;例子&quot;&gt;例子&lt;/h2&gt;

&lt;p&gt;这个例子讲解cuda如何编译到可执行文件中&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;编写一个包含kernel以及kernel调用的.cu文件，输入一下命令&lt;/p&gt;

    &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;nvcc &lt;span class=&quot;nt&quot;&gt;-cuda&lt;/span&gt; p46.cu &lt;span class=&quot;nt&quot;&gt;--keep&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;或者下面的命令：&lt;/p&gt;

    &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;nvcc &lt;span class=&quot;nt&quot;&gt;--compile-only&lt;/span&gt; p46.cu &lt;span class=&quot;nt&quot;&gt;--keep&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--dryrun&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--verbose&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;输出的结果：&lt;/p&gt;

    &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#$ _SPACE_= &lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#$ _CUDART_=cudart&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#$ _HERE_=/usr/local/cuda/bin&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#$ _THERE_=/usr/local/cuda/bin&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#$ _TARGET_SIZE_=&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#$ _TARGET_DIR_=&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#$ _TARGET_SIZE_=64&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#$ TOP=/usr/local/cuda/bin/..&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#$ NVVMIR_LIBRARY_DIR=/usr/local/cuda/bin/../nvvm/libdevice&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#$ LD_LIBRARY_PATH=/usr/local/cuda/bin/../lib:/usr/local/cuda/lib64:&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#$ PATH=/usr/local/cuda/bin/../nvvm/bin:/usr/local/cuda/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#$ INCLUDES=&quot;-I/usr/local/cuda/bin/..//include&quot;  &lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#$ LIBRARIES=  &quot;-L/usr/local/cuda/bin/..//lib64/stubs&quot; &quot;-L/usr/local/cuda/bin/..//lib64&quot;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#$ CUDAFE_FLAGS=&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#$ PTXAS_FLAGS=&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#$ gcc -std=c++14 -D__CUDA_ARCH__=300 -E -x c++  -DCUDA_DOUBLE_MATH_FUNCTIONS -D__CUDACC__ -D__NVCC__  &quot;-I/usr/local/cuda/bin/..//include&quot;    -D__CUDACC_VER_MAJOR__=10 -D__CUDACC_VER_MINOR__=0 -D__CUDACC_VER_BUILD__=130 -include &quot;cuda_runtime.h&quot; -m64 &quot;p46.cu&quot; &amp;gt; &quot;p46.cpp1.ii&quot; &lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#$ cicc --c++14 --gnu_version=70500 --allow_managed   -arch compute_30 -m64 -ftz=0 -prec_div=1 -prec_sqrt=1 -fmad=1 --include_file_name &quot;p46.fatbin.c&quot; -tused -nvvmir-library &quot;/usr/local/cuda/bin/../nvvm/libdevice/libdevice.10.bc&quot; --gen_module_id_file --module_id_file_name &quot;p46.module_id&quot; --orig_src_file_name &quot;p46.cu&quot; --gen_c_file_name &quot;p46.cudafe1.c&quot; --stub_file_name &quot;p46.cudafe1.stub.c&quot; --gen_device_file_name &quot;p46.cudafe1.gpu&quot;  &quot;p46.cpp1.ii&quot; -o &quot;p46.ptx&quot;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#$ ptxas -arch=sm_30 -m64  &quot;p46.ptx&quot;  -o &quot;p46.sm_30.cubin&quot; &lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#$ fatbinary --create=&quot;p46.fatbin&quot; -64 &quot;--image=profile=sm_30,file=p46.sm_30.cubin&quot; &quot;--image=profile=compute_30,file=p46.ptx&quot; --embedded-fatbin=&quot;p46.fatbin.c&quot; --cuda&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#$ gcc -std=c++14 -E -x c++ -D__CUDACC__ -D__NVCC__  &quot;-I/usr/local/cuda/bin/..//include&quot;    -D__CUDACC_VER_MAJOR__=10 -D__CUDACC_VER_MINOR__=0 -D__CUDACC_VER_BUILD__=130 -include &quot;cuda_runtime.h&quot; -m64 &quot;p46.cu&quot; &amp;gt; &quot;p46.cpp4.ii&quot; &lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#$ cudafe++ --c++14 --gnu_version=70500 --allow_managed  --m64 --parse_templates --gen_c_file_name &quot;p46.cudafe1.cpp&quot; --stub_file_name &quot;p46.cudafe1.stub.c&quot; --module_id_file_name &quot;p46.module_id&quot; &quot;p46.cpp4.ii&quot; &lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#$ gcc -std=c++14 -D__CUDA_ARCH__=300 -c -x c++  -DCUDA_DOUBLE_MATH_FUNCTIONS &quot;-I/usr/local/cuda/bin/..//include&quot;   -m64 -o &quot;p46.o&quot; &quot;p46.cudafe1.cpp&quot; &lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;其中keep表示保留中间结果。&lt;/p&gt;

    &lt;p&gt;在相应的目录下有如下的结果：&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/images/posts/2020-05-15-09-52-27-build_result.png&quot; alt=&quot;编译结果&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;拆解一下上面终端的输出结果：&lt;/p&gt;

    &lt;p&gt;环境变量的什么就不说了&lt;/p&gt;

    &lt;p&gt;1）p46.cu–&amp;gt;p46.cpp1.ii&lt;/p&gt;

    &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#$ gcc -std=c++14 -D__CUDA_ARCH__=300 -E -x c++  -DCUDA_DOUBLE_MATH_FUNCTIONS -D__CUDACC__ -D__NVCC__  &quot;-I/usr/local/cuda/bin/..//include&quot;    -D__CUDACC_VER_MAJOR__=10 -D__CUDACC_VER_MINOR__=0 -D__CUDACC_VER_BUILD__=130 -include &quot;cuda_runtime.h&quot; -m64 &quot;p46.cu&quot; &amp;gt; &quot;p46.cpp1.ii&quot; &lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;2）p46.cpp1.ii—&amp;gt;p46.ptx&lt;/p&gt;

    &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#$ cicc --c++14 --gnu_version=70500 --allow_managed   -arch compute_30 -m64 -ftz=0 -prec_div=1 -prec_sqrt=1 -fmad=1 --include_file_name &quot;p46.fatbin.c&quot; -tused -nvvmir-library &quot;/usr/local/cuda/bin/../nvvm/libdevice/libdevice.10.bc&quot; --gen_module_id_file --module_id_file_name &quot;p46.module_id&quot; --orig_src_file_name &quot;p46.cu&quot; --gen_c_file_name &quot;p46.cudafe1.c&quot; --stub_file_name &quot;p46.cudafe1.stub.c&quot; --gen_device_file_name &quot;p46.cudafe1.gpu&quot;  &quot;p46.cpp1.ii&quot; -o &quot;p46.ptx&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;3）ptx–&amp;gt;cubin&lt;/p&gt;

    &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#$ ptxas -arch=sm_30 -m64  &quot;p46.ptx&quot;  -o &quot;p46.sm_30.cubin&quot; &lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;4）cubin–&amp;gt;fatbin&lt;/p&gt;

    &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#$ fatbinary --create=&quot;p46.fatbin&quot; -64 &quot;--image=profile=sm_30,file=p46.sm_30.cubin&quot; &quot;--image=profile=compute_30,file=p46.ptx&quot; --embedded-fatbin=&quot;p46.fatbin.c&quot; --cuda&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;5）cpp–&amp;gt;cpp4.ii&lt;/p&gt;

    &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#$ gcc -std=c++14 -E -x c++ -D__CUDACC__ -D__NVCC__  &quot;-I/usr/local/cuda/bin/..//include&quot;    -D__CUDACC_VER_MAJOR__=10 -D__CUDACC_VER_MINOR__=0 -D__CUDACC_VER_BUILD__=130 -include &quot;cuda_runtime.h&quot; -m64 &quot;p46.cu&quot; &amp;gt; &quot;p46.cpp4.ii&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;6）&lt;/p&gt;

    &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#$ cudafe++ --c++14 --gnu_version=70500 --allow_managed  --m64 --parse_templates --gen_c_file_name &quot;p46.cudafe1.cpp&quot; --stub_file_name &quot;p46.cudafe1.stub.c&quot; --module_id_file_name &quot;p46.module_id&quot; &quot;p46.cpp4.ii&quot; &lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;7）&lt;/p&gt;

    &lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;gcc &lt;span class=&quot;nt&quot;&gt;-std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;c++14 &lt;span class=&quot;nt&quot;&gt;-D__CUDA_ARCH__&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;300 &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-x&lt;/span&gt; c++  &lt;span class=&quot;nt&quot;&gt;-DCUDA_DOUBLE_MATH_FUNCTIONS&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;-I/usr/local/cuda/bin/..//include&quot;&lt;/span&gt;   &lt;span class=&quot;nt&quot;&gt;-m64&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;p46.o&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;p46.cudafe1.cpp&quot;&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;查看p46.ptx以及p46.sm_30.cubin&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;//&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// Generated by NVIDIA NVVM Compiler&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// Compiler Build ID: CL-24817639&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// Cuda compilation tools, release 10.0, V10.0.130&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// Based on LLVM 3.4svn&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;version&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;6.3&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sm_30&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;address_size&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;

	&lt;span class=&quot;c1&quot;&gt;// .globl	_Z3addiiPi&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;visible&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;entry&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_Z3addiiPi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u32&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_Z3addiiPi_param_0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u32&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_Z3addiiPi_param_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u64&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_Z3addiiPi_param_2&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b32&lt;/span&gt; 	&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reg&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b64&lt;/span&gt; 	&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;


	&lt;span class=&quot;n&quot;&gt;ld&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u32&lt;/span&gt; 	&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_Z3addiiPi_param_0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;ld&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u32&lt;/span&gt; 	&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_Z3addiiPi_param_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;ld&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u64&lt;/span&gt; 	&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rd1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_Z3addiiPi_param_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;cvta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;global&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u64&lt;/span&gt; 	&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rd2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rd1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s32&lt;/span&gt; 	&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;global&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u32&lt;/span&gt; 	&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rd2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;&lt;strong&gt;cubin&lt;/strong&gt; ， &lt;strong&gt;ptx&lt;/strong&gt; 是如何组织到 &lt;strong&gt;exe&lt;/strong&gt; 中，又是如何被加载到驱动中去的&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;编译选项&quot;&gt;编译选项&lt;/h1&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;这里有很多的编译选项，可以显示很多的有用信息&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;gpu-汇编&quot;&gt;GPU 汇编&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2020-05-16-09-49-40-virtual_and_real.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;通过编译查看kernel的资源使用&quot;&gt;通过编译查看kernel的资源使用&lt;/h1&gt;

&lt;p&gt;命令如下：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;nvcc &lt;span class=&quot;nt&quot;&gt;--resource-usage&lt;/span&gt; p46.cu
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;结果如下：&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'_Z3addiiPi'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'sm_30'&lt;/span&gt;
ptxas info    : Function properties &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;_Z3addiiPi
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 5 registers, 336 bytes cmem[0]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As shown in the above example, the amounts of statically allocated global memory (gmem) and constant memory in bank 0 (cmem) are listed.&lt;/p&gt;

&lt;p&gt;stack fram是每个线程的堆栈使用量。溢出存储和加载表示在堆栈内存上完成的存储和加载，这些存储和加载用于存储不能分配给物理寄存器的变量。&lt;/p&gt;
</description>
        <pubDate>Sat, 09 May 2020 14:29:00 +0800</pubDate>
        <link>http://localhost:4000/2020/05/cuda%E7%9A%84%E7%BC%96%E8%AF%91/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/05/cuda%E7%9A%84%E7%BC%96%E8%AF%91/</guid>
        
        <category>GPU</category>
        
        
      </item>
    
      <item>
        <title>cuda的最佳实践</title>
        <description>&lt;p&gt;[TOC]&lt;/p&gt;

&lt;h1 id=&quot;简介&quot;&gt;简介&lt;/h1&gt;

&lt;p&gt;这个是用来指导如何从gpu中获取最好的性能。&lt;/p&gt;

&lt;p&gt;一般的优化是按照下面的流程来的：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2020-05-09-08-31-34-APOD.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;评估：识别算法的瓶颈，评估热点函数，确定工作量&lt;/p&gt;

&lt;p&gt;并行化：开发cuda代码或者调用现有的cuda相关的库：cuBLAS等&lt;/p&gt;

&lt;p&gt;优化：慢慢来&lt;/p&gt;

&lt;p&gt;部署：&lt;/p&gt;

&lt;h2 id=&quot;异构计算&quot;&gt;异构计算&lt;/h2&gt;

&lt;p&gt;主机和设备之间的区别：主要是线程模型以及物理存储&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;线程资源&lt;/li&gt;
  &lt;li&gt;线程：cpu切换线程代价比gpu上切换线程要大&lt;/li&gt;
  &lt;li&gt;RAM&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;考虑下面的情况，两个N*N的矩阵&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;加法运算：NxN的计算，搬运数据是3NxN&lt;/li&gt;
  &lt;li&gt;乘法运算：N×NxN的计算&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;优化的建议&quot;&gt;优化的建议&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;最高优先级：为了最大程度地提高开发人员的生产力，请对应用程序进行性能分析，以确定热点和瓶颈。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;最高优先级: To get the maximum benefit from CUDA, focus first on finding ways to
parallelize sequential code.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;profile&quot;&gt;Profile&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;先用gprof来识别出c++代码（cpu）中的热点&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;利用Amdahl’s or Gustafson’s Law来确定算法加速的上界&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;并行化&quot;&gt;并行化&lt;/h2&gt;

&lt;p&gt;几种把代码并行化的策略&lt;/p&gt;

&lt;h3 id=&quot;并行库&quot;&gt;并行库&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;cuBLAS&lt;/li&gt;
  &lt;li&gt;cuFFT&lt;/li&gt;
  &lt;li&gt;Thrust：扫描、排序、规约&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;设置并行编译选项&quot;&gt;设置并行编译选项&lt;/h3&gt;

&lt;p&gt;通过设置编译选项来使得代码并行化&lt;/p&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;&lt;strong&gt;OpenACC？这个是标准是什么？&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;编写cuda代码&quot;&gt;编写cuda代码&lt;/h3&gt;

&lt;h1 id=&quot;获取正确的结果&quot;&gt;获取正确的结果&lt;/h1&gt;

&lt;h2 id=&quot;debug&quot;&gt;Debug&lt;/h2&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;cuda-gdb 这个要用起来&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;性能指标metrics&quot;&gt;性能指标（Metrics）&lt;/h1&gt;

&lt;p&gt;在优化cuda代码的时候，需要了解如何准确地测量性能以及性能在整体中扮演的角色。&lt;/p&gt;

&lt;h2 id=&quot;时间&quot;&gt;时间&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;cpu时间&lt;/strong&gt;&lt;/p&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;如何测量cpu的时间&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;gpu时间&lt;/strong&gt;&lt;/p&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;如何测量gpu的时间&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;带宽&quot;&gt;带宽&lt;/h2&gt;

&lt;p&gt;数据的排布影响数据传输&lt;/p&gt;

&lt;p&gt;为了衡量性能，必须进行理论带宽统计以及实际带宽统计&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;高优先级：在衡量性能和优化收益时，将计算的有效带宽用作度量标准。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;理论带宽的计算&quot;&gt;理论带宽的计算&lt;/h3&gt;

&lt;p&gt;例子：Tesla 使用GDDR5（双数据），1.85GHz，384-bit带宽&lt;/p&gt;

&lt;p&gt;177.6GB/s=(1.85&lt;em&gt;10”9&lt;/em&gt;(348/8)*2/10”9)—其中“表示幂&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;公式：&lt;/strong&gt;
\(带宽=(GHz*带宽/8*2)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注意：启用ECC时，有效的最大带宽会因内存校验和的额外流量而减少大约20％，尽管ECC对带宽的确切影响取决于内存访问模式。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;实际带宽的计算&quot;&gt;实际带宽的计算&lt;/h3&gt;

&lt;p&gt;公式：&lt;/p&gt;

&lt;p&gt;\(有效带宽=(b_r+b_w)/time\)
Br is the number of bytes read per kernel, Bw is the number of bytes written per kernel, and time is given in seconds.&lt;/p&gt;

&lt;h3 id=&quot;通过profiler测量吞吐&quot;&gt;通过Profiler测量吞吐&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Requested Global Load Throughput&lt;/li&gt;
  &lt;li&gt;Requested Global Store Throughput&lt;/li&gt;
  &lt;li&gt;Global Load Throughput、&lt;/li&gt;
  &lt;li&gt;Global Store Throughput&lt;/li&gt;
  &lt;li&gt;DRAM Read Throughput&lt;/li&gt;
  &lt;li&gt;DRAM Write Throughput&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Requested Global Load Throughput 和 Requested Global Store Throughput 表示内核请求的全局显存的吞吐量，和有效带宽计算的值对应。&lt;/p&gt;

&lt;h1 id=&quot;显存优化&quot;&gt;显存优化&lt;/h1&gt;

&lt;p&gt;内存优化是提高性能的最重要领域，通过最大化带宽来最大程度利用硬件。&lt;/p&gt;

&lt;h2 id=&quot;在主机和设备之间的数据传输&quot;&gt;在主机和设备之间的数据传输&lt;/h2&gt;

&lt;p&gt;主机和设备之间传输的带宽（通过PCIE总线 8GB/s）和设备传输的代码差距比较大&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;高优先级：最大限度地减少主机与设备之间的数据传输，即使这意味着在设备上运行某些内核（与在主机CPU上运行这些内核相比）也未显示出性能提升。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;临时数据结构应在设备内存中创建，由设备操作并销毁，而不要被主机映射或复制到主机内存中。&lt;/p&gt;

&lt;p&gt;将每一次小的传输，变成批量的&lt;/p&gt;

&lt;p&gt;当使用页面锁定（或固定）内存时，可以在主机和设备之间获得更高的带宽。&lt;/p&gt;

&lt;p&gt;但是如何设定固定内存？设定太多的固定内存会影响整体的性能。&lt;/p&gt;

&lt;h3 id=&quot;传输和计算异步&quot;&gt;传输和计算异步&lt;/h3&gt;

&lt;p&gt;传输和计算重叠需要固定内存以及stream&lt;/p&gt;

&lt;p&gt;顺序执行&lt;/p&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;cudaMemcpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a_d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sizeof&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;kernel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nThreads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nThreads&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a_d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;异步执行&lt;/p&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;sizeof&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nStreams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nStreams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;offset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nStreams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;cudaMemcpyAsync&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a_d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a_h&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stream&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]);&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;kernel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nThreads&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nStreams&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nThreads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stream&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a_d&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2020-05-11-09-31-01_execute.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;0拷贝&quot;&gt;0拷贝&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;低优先级: Use zero-copy operations on integrated GPUs for CUDA Toolkit version 2.2 and later.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;设备显存空间&quot;&gt;设备显存空间&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2020-05-11-09-39-03-spaces_on_device.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2020-05-12-09-21-55-存储.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2020-05-11-09-41-14-salient_feature_device_memory.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;全局访问&quot;&gt;全局访问&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;最重要的性能考虑因素可能是全局内存访问的合并。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;高优先级：确保在可能的情况下合并全局内存访问。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这里的全局访问需要考虑cache L1 和L2&lt;/p&gt;

&lt;p&gt;注意：For devices of compute capability 3.x, accesses to global memory are cached only in L2;
L1 is reserved for local memory accesses. Some devices of compute capability 3.5, 3.7, or 5.2 allow opt-in caching of globals in L1 as well.&lt;/p&gt;

&lt;p&gt;针对于启用ECC的，也会有影响&lt;/p&gt;

&lt;p&gt;顺序对齐的访问模式，如下所示&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2020-05-11_09-52-38-address_warp.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如果任何线程未请求该行的某些单词（例如，如果多个线程访问了同一单词，或者某些线程未参与访问），则无论如何都将获取高速缓存行中的所有数据。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2020-05-11-09-55-43-misaligned_access.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这里使用了两个128byte L1 cache lines&lt;/p&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;如何做下面的实验呢？并且测量相应的带宽？&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;copy&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;that&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;illustrates&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;misaligned&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accesses&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;__global__&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;offsetCopy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;odata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blockIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blockDim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threadIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;odata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;strided 访问&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;illustrate&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;non&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unit&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;copy&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;__global__&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;strideCopy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;odata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;blockIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;blockDim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threadIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;odata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2020-05-11-10-16-44-stride_access.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;跨度为2导致负载/存储效率为50％，因为未使用事务中的一半元素，这代表了浪费的带宽。 随着步幅的增加，有效带宽减小，直到为经线中的32个线程加载32行缓存为止。如图8所示。&lt;/p&gt;

&lt;h3 id=&quot;共享内存&quot;&gt;共享内存&lt;/h3&gt;

&lt;p&gt;[]: https://devblogs.nvidia.com/using-shared-memory-cuda-cc/	“ NVIDA”&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;每个SM都有与其关联的相当少量的共享内存，通常为16KB的内存&lt;/strong&gt;。如果每个SM具有16KB的共享内存，并且在一个SM上同时运行4个线程块，则每个线程块可用的最大共享内存量将为16KB / 4（4KB）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2020-05-12-09-24-17-共享内存.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在kernel中声明共享内存的方式有多种，具体取决于在编译时还是在运行时知道内存量。&lt;/p&gt;

&lt;p&gt;共享内存被分为大小一样的内存banks，并且能同时访问。&lt;/p&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;什么是banks冲突&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2020-05-12-10-09-01-bancks-confliks.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;为了最大程度地减少banks冲突，重要的是要了解存储器地址如何映射到banks以及如何优化调度存储请求。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;so bank conflicts can occur between any threads in the warp&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;写一个这样的例子进行运行&lt;/p&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;__global__&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;simpleMultiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blockIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blockDim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threadIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blockIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blockDim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threadIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TILE_DIM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TILE_DIM&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;it is necessary to consider how warps access global memory in the for loop.&lt;/p&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;__global__&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;coalescedMultiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;__shared__&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aTile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TILE_DIM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TILE_DIM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blockIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blockDim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threadIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blockIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blockDim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threadIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;aTile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;threadIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;threadIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TILE_DIM&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;threadIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TILE_DIM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aTile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;threadIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;each element in a tile of A is read from global memory only once, in a fully coalesced fashion (with no wasted bandwidth), to shared memory.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;这说明了当硬件L1高速缓存逐出策略与应用程序的需求不完全匹配时，或者当L1高速缓存不用于从全局内存中读取数据时，将共享内存用作用户管理的高速缓存。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2020-05-12-10-13-13-冲突.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2020-05-12 10-14-31-foure-confile.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;__global__&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sharedABMultiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;__shared__&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aTile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TILE_DIM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TILE_DIM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;bTile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TILE_DIM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TILE_DIM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blockIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blockDim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threadIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blockIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blockDim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threadIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;aTile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;threadIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;threadIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TILE_DIM&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;threadIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;bTile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;threadIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;threadIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;threadIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;__syncthreads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TILE_DIM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aTile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;threadIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bTile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;threadIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;这里需要把这个写成一个例子进行验证对比（P48)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;使用共享内存的三大原因：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;允许合并访问全局内存&lt;/li&gt;
  &lt;li&gt;从全局内存中消除冗余负载&lt;/li&gt;
  &lt;li&gt;为了避免浪费带宽&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;局部存储&quot;&gt;局部存储&lt;/h3&gt;

&lt;p&gt;局部存储并不是代表访问它是很快&lt;/p&gt;

&lt;h3 id=&quot;文本内存&quot;&gt;文本内存&lt;/h3&gt;

&lt;p&gt;文本存储是cached，在kernel调用中，纹理缓存与全局内存写入之间的一致性并不保持一致。&lt;/p&gt;

&lt;h3 id=&quot;常量内存&quot;&gt;常量内存&lt;/h3&gt;

&lt;p&gt;64KB&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The constant memory space is cached&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&quot;执行优化&quot;&gt;执行优化&lt;/h1&gt;

&lt;p&gt;这里关键的是让处理器（sm)尽可能的忙起来，这里的关键概念是并发率&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;中等优先级。为了隐藏由寄存器依赖性引起的延迟，每个多处理器保持足够的活动线程数量（即足够的占用率）。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;中等优先级。每个区块的线程数应该是32个线程的倍数，因为这样可以提供最佳的计算效率，并且有利于凝聚。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;并发率occupancy&quot;&gt;并发率（Occupancy）&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Some metric related to the number of active warps on a multiprocessor is therefore important in determining how effectively the hardware is kept busy. This metric is occupancy.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;更高的占用率并不总是等同于更高的性能，在这一点上，额外的占用率并不能提高性能。 但是，低占用率总是会干扰隐藏内存延迟的能力，从而导致性能下降。&lt;/p&gt;

&lt;p&gt;影响占用率的因素：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;寄存器：So, if each thread block uses many registers, the number of thread blocks that can be resident
on a multiprocessor is reduced, thereby lowering the occupancy of the multiprocessor。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;数据传输和kener执行的重叠&lt;/p&gt;

&lt;h2 id=&quot;多个上下文context&quot;&gt;多个上下文（context）&lt;/h2&gt;

&lt;p&gt;如果多个CUDA应用进程同时访问同一个GPU，这几乎总是意味着多个上下文，因为除非使用&lt;strong&gt;CUDA多进程服务&lt;/strong&gt;，否则一个上下文被绑定到一个特定的主机进程。&lt;/p&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;cuda多进程服务指的是什么？&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当上下文切换的频繁的时候，会降低利用率&lt;/p&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;主上下文（primary context)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;block以及threads的数量&quot;&gt;block以及threads的数量&lt;/h2&gt;

&lt;p&gt;每个网格的块的尺寸和大小以及每个块的warp的尺寸和大小都是重要的因素。&lt;/p&gt;

&lt;p&gt;When choosing the first execution configuration parameter-the number of blocks per grid, or grid size the primary concern is keeping the entire GPU busy. The number of blocks in a grid should be larger than the number of multiprocessors so that all multiprocessors have at least one block to execute.&lt;/p&gt;

&lt;p&gt;Notify：&lt;strong&gt;例如，将占用率从66%提高到100%，一般情况下并不会带来相同类比的性能提升。占用率较低kenerl的每个线程的可用寄存器数会比高占用率的内核多。这可能导致更少的寄存器溢出到本地内存。通常情况下，一旦占用了达到了50%，额外增加的占用率并不会转化为提高了性能。在某些情况下，即使是在某些情况下，也可以完全覆盖延时，甚至是 更少的翘曲，特别是通过指令级并行化(ILP)。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;经验法则：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;每个块的线程应该是warp大小的倍数，以避免浪费计算时间。&lt;/li&gt;
  &lt;li&gt;每个块至少应使用64个线程，并且只有在有多个每个多处理器的并发块。&lt;/li&gt;
  &lt;li&gt;每块128到256个线程之间是一个比较好的选择，也是一个很好的初始范围。使用不同尺寸的线块进行实验。&lt;/li&gt;
  &lt;li&gt;使用几个（3到4个）小线块，而不是每个大线块。如果延迟影响到性能，多处理器的性能。这对以下几点特别有利经常调用__syncthreads()的内核。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;共享内存-1&quot;&gt;共享内存&lt;/h2&gt;

&lt;p&gt;确定性能对占用率的敏感度的一个有用的技术是通过试验动态分配的共享内存的数量来确定性能对占用率的敏感度，这在执行配置的第三个参数中规定了。通过简单地增加这个参数（不修改内核），可以有效地降低内核的占用率，并测量其对性能的影响。&lt;/p&gt;

&lt;h1 id=&quot;指令优化&quot;&gt;指令优化&lt;/h1&gt;

&lt;p&gt;对于指令的优化，最好的做法就是在高优先级的优化之后在进行&lt;/p&gt;

&lt;h2 id=&quot;算术指令&quot;&gt;算术指令&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;低优先级：使用移位操作，避免昂贵的除法和模数计算。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;中等优先级:只要速度高于精度，就使用快速数学库。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;____sinf(x) and ____expf(x)). Functions following functionName() naming convention are slower but have higher accuracy (e.g., sinf(x) and expf(x)). “&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The -use_fast_math compiler option of nvcc coerces every functionName() call to the equivalent __functionName() call..&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;内存指令&quot;&gt;内存指令&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;高优先级：尽量减少对全局内存的使用。尽可能选择共享内存访问。&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&quot;控制流&quot;&gt;控制流&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;高优先级:避免同一warp内的不同执行路径。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;低优先级：使编译器能够很容易地使用分支预测来代替循环或控制语句。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;中低优先级：使用有符号整数而不是无符号整数作为循环计数器。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;高优先级：避免在分支代码内部使用__syncthreads()。&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&quot;了解编程环境&quot;&gt;了解编程环境&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2020-05-14-08-39-36-platformPackage.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;总结&quot;&gt;总结&lt;/h1&gt;

&lt;p&gt;三个基本策略：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Maximizing parallel execution&lt;/li&gt;
  &lt;li&gt;Optimizing memory usage to achieve maximum memory bandwidth&lt;/li&gt;
  &lt;li&gt;Optimizing instruction usage to achieve maximum instruction throughput&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Sat, 09 May 2020 14:29:00 +0800</pubDate>
        <link>http://localhost:4000/2020/05/cuda%E7%9A%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/05/cuda%E7%9A%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</guid>
        
        <category>GPU</category>
        
        
      </item>
    
      <item>
        <title>Cuda的理解</title>
        <description>
&lt;hr /&gt;
&lt;p&gt;layout: post&lt;/p&gt;

&lt;p&gt;title:  “cuda的理解”&lt;/p&gt;

&lt;p&gt;date:   2020-05-05 14:29&lt;/p&gt;

&lt;p&gt;excerpt:&lt;/p&gt;

&lt;p&gt;tag:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;h2 id=&quot;gpu&quot;&gt;GPU&lt;/h2&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;简介&quot;&gt;简介&lt;/h1&gt;

&lt;p&gt;gpu的演化过程&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2020-05-06-08-54-47-cpu-gpu.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;三个抽象&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;线程组&lt;/li&gt;
  &lt;li&gt;共享内存&lt;/li&gt;
  &lt;li&gt;同步屏障&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这些抽象提供了&lt;strong&gt;数据并行性&lt;/strong&gt;以及&lt;strong&gt;线程并行性&lt;/strong&gt;。把一个大问题变成了很多个的子问题。实际上，可以在任何可用的多处理器上调度每个线程块在GPU中以&lt;strong&gt;任何顺序（并发或顺序）&lt;/strong&gt;进行操作，以便编译后的CUDA程序可以在任何数量的多处理器上执行。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/2020-05-06-09-22-59-调度.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;编程模型&quot;&gt;编程模型&lt;/h1&gt;

&lt;h2 id=&quot;kernel&quot;&gt;kernel&lt;/h2&gt;

&lt;p&gt;含义：就是一个c函数，能被N个不同的线程执行N次&lt;/p&gt;

&lt;p&gt;定义：&lt;/p&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;function_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;blockx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;thriedx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,...)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Q：线程数是不是可以设置很多？它依赖于什么呢？若是设置超过了规定，执行起来会是什么样呢？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;每一个kernel还有一个Grid，一个grid含有多个block，一个block含有多个thread&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;block的执行是以任何顺序来调度执行。&lt;/p&gt;

&lt;h2 id=&quot;显存的层次&quot;&gt;显存的层次&lt;/h2&gt;

&lt;p&gt;grid中访问的是全局&lt;/p&gt;

&lt;p&gt;block访问的是共享内存&lt;/p&gt;

&lt;p&gt;thread访问的是自己的内存&lt;/p&gt;

&lt;p&gt;还有常量内存以及文本内存&lt;/p&gt;

&lt;h1 id=&quot;编程接口&quot;&gt;编程接口&lt;/h1&gt;

&lt;h2 id=&quot;cuda编译的流程&quot;&gt;cuda编译的流程&lt;/h2&gt;

&lt;h3 id=&quot;ptx&quot;&gt;PTX&lt;/h3&gt;

&lt;p&gt;指令集架构&lt;/p&gt;

&lt;h3 id=&quot;nvcc&quot;&gt;NVCC&lt;/h3&gt;

&lt;p&gt;—&amp;gt; PTX code&lt;/p&gt;

&lt;p&gt;—&amp;gt; cubin object&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;use the CUDA driver API (see Driver API) to load and execute the PTX code or cubin object.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Q：如何编译PTX，如何查看编译过后可执行文件？查看它的反汇编&lt;/p&gt;

&lt;p&gt;-code —-&amp;gt; 表示 cubin objec在要在哪个目标下运行，例如：&lt;/p&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;code&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sm_35&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;//produces binary code for devices of compute capability 3.5&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;-arch—-&amp;gt;表示PTX的编译情况&lt;/p&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compute_30&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;显存的分配方式&quot;&gt;显存的分配方式&lt;/h3&gt;

&lt;p&gt;cudaMalloc&lt;/p&gt;

&lt;p&gt;cudaMallocPitch&lt;/p&gt;

&lt;p&gt;cudaMalloc3D&lt;/p&gt;

&lt;p&gt;cudaHostAlloc&lt;/p&gt;

&lt;p&gt;使用固定内存的好处？&lt;/p&gt;

&lt;h3 id=&quot;streams&quot;&gt;streams&lt;/h3&gt;

&lt;p&gt;这个该如何理解呢？&lt;/p&gt;

&lt;h3 id=&quot;显示同步&quot;&gt;显示同步&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;cudaDeviceSynchronize()&lt;/li&gt;
  &lt;li&gt;cudaStreamSynchronize()&lt;/li&gt;
  &lt;li&gt;cudaStreamWaitEvent()&lt;/li&gt;
  &lt;li&gt;cudaStreamQuery()&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;隐是同步&quot;&gt;隐是同步&lt;/h3&gt;

&lt;p&gt;Two commands from different streams cannot run concurrently。&lt;/p&gt;

&lt;h3 id=&quot;行为并行&quot;&gt;行为并行&lt;/h3&gt;

&lt;p&gt;如何在stream进行测量，多个stream中的并行呢？&lt;/p&gt;

&lt;p&gt;stream也是有优先级的，设置优先级。&lt;/p&gt;

&lt;h2 id=&quot;图&quot;&gt;图&lt;/h2&gt;

&lt;p&gt;这个很重要，该如何理解呢？&lt;/p&gt;

&lt;p&gt;图的优势：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;减少cpu launch的时间，与stream相比，因为许多操作是预先定义好的&lt;/li&gt;
  &lt;li&gt;在GPU上实现了整个工作流程，能更好的优化，比stream阶段性的提交。&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;使用图，分为三个阶段：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;定义图&lt;/li&gt;
  &lt;li&gt;实例化图&lt;/li&gt;
  &lt;li&gt;执行图&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;图的结构：图中一个节点表示一个操作，操作之间的依赖就是连接，这些依赖规定了操作的执行顺序。&lt;/p&gt;

&lt;p&gt;节点的类型：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;kernel&lt;/li&gt;
  &lt;li&gt;cpu function call&lt;/li&gt;
  &lt;li&gt;memroy copy&lt;/li&gt;
  &lt;li&gt;memset&lt;/li&gt;
  &lt;li&gt;empty node&lt;/li&gt;
  &lt;li&gt;child graph&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;创建图的方式：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;API&lt;/li&gt;
  &lt;li&gt;streeam capture&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;事件&quot;&gt;事件&lt;/h3&gt;

&lt;p&gt;事件的作用是什么？&lt;/p&gt;

&lt;h3 id=&quot;多显卡&quot;&gt;多显卡&lt;/h3&gt;

&lt;p&gt;显卡之间的访问，&lt;/p&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;cudaDeviceCanAccessPeer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;统一内存访问空间&quot;&gt;统一内存访问空间&lt;/h3&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;nifiedAddressing&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;进程间通信&quot;&gt;进程间通信&lt;/h3&gt;

&lt;p&gt;cuda IPC&lt;/p&gt;

&lt;h3 id=&quot;错误&quot;&gt;错误&lt;/h3&gt;

&lt;p&gt;如何检查GPU的运行时错误？&lt;/p&gt;

&lt;h1 id=&quot;硬件实现&quot;&gt;硬件实现&lt;/h1&gt;

&lt;p&gt;GPU是围绕着多个SMs（Streaming Multiprocessors）来构造体系的。NVIDIA GPU架构使用小端表示。&lt;/p&gt;

&lt;h3 id=&quot;simt架构&quot;&gt;&lt;strong&gt;SIMT架构&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;warp的含义是什么？32？&lt;/p&gt;

&lt;p&gt;每一个block能分为多个warp来调度呢？&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The total number of registers and total amount of shared memory allocated for a block
are documented in the CUDA Occupancy Calculator provided in the CUDA Toolkit.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;hardware-multithreading&quot;&gt;Hardware Multithreading&lt;/h3&gt;

&lt;h1 id=&quot;性能准则&quot;&gt;性能准则&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;三个基本策略&lt;/strong&gt;：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;最大化并行，提高最大的利用率&lt;/li&gt;
  &lt;li&gt;优化内存，提高内存的吞吐量&lt;/li&gt;
  &lt;li&gt;优化指令利用，提高最大的指令吞吐量&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;最大化利用率&quot;&gt;最大化利用率&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;应用层面&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;设备层面&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;通过使用stream，让设备尽可能的忙碌起来&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;SM级别&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在这个级别中，利用率与常驻warp的数量直接相关。&lt;/p&gt;

&lt;p&gt;warp尚未准备好执行其下一条指令的最常见原因是该指令的输入操作数尚不可用。&lt;/p&gt;

&lt;p&gt;Warp未准备好执行下一条指令的另一个原因是它正在等待在某些内存栅栏（“内存栅栏功能”）或同步点（“内存”围栏功能）。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;给定内核的每个多处理器上存在的块和warp数调用取决于调用的执行配置（执行配置），多处理器的内存资源，以及内核的资源需求为硬件多线程中描述。 报告寄存器和共享内存使用情况使用-ptxas-options = -v选项进行编译时由编译器执行。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;占用率计算&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cudaOccupancyMaxActiveBlocksPerMultiprocessor()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// Device code&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;__global__&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;MyKernel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threadIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blockIdx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blockDim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// Host code&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(){&lt;/span&gt;
    
   &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numBlocks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// Occupancy in terms of active blocks&lt;/span&gt;
   &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blockSize&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
   &lt;span class=&quot;c1&quot;&gt;// These variables are used to convert occupancy to warps&lt;/span&gt;
   &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;cudaDeviceProp&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
   &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activeWarps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
   &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxWarps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;cudaGetDevice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;cudaGetDeviceProperties&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;cudaOccupancyMaxActiveBlocksPerMultiprocessor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                                                 &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numBlocks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                                  &lt;span class=&quot;n&quot;&gt;MyKernel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                                  &lt;span class=&quot;n&quot;&gt;blockSize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                                 &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;activeWarps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numBlocks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blockSize&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;warpSize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;maxWarps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maxThreadsPerMultiProcessor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;warpSize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Occupancy: &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;double&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;activeWarps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxWarps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;%&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;
   &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;endl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;在cuda/tool/CUDA_Occupancy_Calculator.xls&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;显存访问&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;显存的访问对于warp的执行有很多的影响&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;全局显存的访问&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;32\64\128字节的对齐，对于warp中每一个线程访问全局，将会合并成一次或者多次的显存访问。&lt;/p&gt;

&lt;p&gt;对于大小和对齐的要求：如果未满足此大小和对齐要求，则访问将编译为具有交错访问模式的多个指令，从而导致这些指令无法完全合并。 因此，建议对驻留在全局内存中的数据使用符合此要求的类型。&lt;/p&gt;

&lt;p&gt;对于二维数据的访问，如下所示：&lt;/p&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;BaseAddress&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; checked=&quot;checked&quot; /&gt;&lt;strong&gt;为了使这些访问完全合并，线程块的宽度和数组的宽度都必须是经线大小的倍数。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;局部内存&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Also, the compiler reports total local memory usage per kernel (lmem) when compiling with the **–ptxas-options=-v **option.&lt;/p&gt;

&lt;p&gt;如何在cmake中增加这个选项表示出来呢？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;常量内存&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;最大化指令吞吐率&quot;&gt;最大化指令吞吐率&lt;/h2&gt;

&lt;p&gt;在本节中，吞吐量以每个SM每个时钟周期的操作数给出。 对于32的warp大小，一个指令对应32个操作，因此，如果N是每个时钟周期的操作数，则指令吞吐量为每个时钟周期N / 32指令。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;cuobjdump can be used to inspect a particular implementation in a cubin object.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在if\switch\do\for\while会影响到指令的吞吐率，导致线程执行分叉。最简单的方式的是用&lt;strong&gt;thread.idx/warpsize&lt;/strong&gt;来进行控制。&lt;/p&gt;

&lt;p&gt;同步指令的影响&lt;/p&gt;

&lt;h1 id=&quot;语言扩展&quot;&gt;语言扩展&lt;/h1&gt;

&lt;p&gt;内建vector类型&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;如何使用Tensor Cores&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;–Sub-byte WMMA operations provide a way to access the low-precision capabilities of
Tensor Cores. –&lt;/p&gt;

&lt;p&gt;cuda core 和 tensor cores 的区别？&lt;/p&gt;

</description>
        <pubDate>Wed, 06 May 2020 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/2020/05/cuda%E7%9A%84%E7%90%86%E8%A7%A3/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/05/cuda%E7%9A%84%E7%90%86%E8%A7%A3/</guid>
        
        
      </item>
    
      <item>
        <title>空荡荡的地球－全球人口下降的冲击</title>
        <description>&lt;h1 id=&quot;简介&quot;&gt;简介&lt;/h1&gt;

&lt;p&gt;关于人口的书籍&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;中世界，90%的欧洲人生活在农场，伴随工业革命，将人集中在城市中。在农场中，多一双手就是多一份投资，但是在城市，多一个孩子，多一张需要养活的嘴巴&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;多样性是发明创造的真正的母亲&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;经济不确定性是一种强有力的节育形式，这也解释什么现在很多人不愿意生孩子&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;良好的公共政策总是建立在共同的自身利益上，我们每一个人都为自己而存在&lt;/p&gt;

&lt;hr /&gt;

</description>
        <pubDate>Tue, 05 May 2020 14:29:00 +0800</pubDate>
        <link>http://localhost:4000/2020/05/%E7%A9%BA%E8%8D%A1%E8%8D%A1%E7%9A%84%E5%9C%B0%E7%90%83-%E5%85%A8%E7%90%83%E4%BA%BA%E5%8F%A3%E4%B8%8B%E9%99%8D%E7%9A%84%E5%86%B2%E5%87%BB/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/05/%E7%A9%BA%E8%8D%A1%E8%8D%A1%E7%9A%84%E5%9C%B0%E7%90%83-%E5%85%A8%E7%90%83%E4%BA%BA%E5%8F%A3%E4%B8%8B%E9%99%8D%E7%9A%84%E5%86%B2%E5%87%BB/</guid>
        
        <category>社科</category>
        
        
      </item>
    
      <item>
        <title>智识分子</title>
        <description>&lt;h1 id=&quot;简介&quot;&gt;简介&lt;/h1&gt;

&lt;p&gt;关于讨论关于如何理解现代世界的书，作者在这本书中讲了一些现代人应该有，而且只有现代人才可能有的“智识”——智慧和见识&lt;/p&gt;

&lt;h1 id=&quot;文中的观点&quot;&gt;文中的观点&lt;/h1&gt;

&lt;p&gt;三个趋势&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;世界越来越复杂&lt;/li&gt;
  &lt;li&gt;人工智能正在慢慢取代人的工作&lt;/li&gt;
  &lt;li&gt;尽管所有人的物质生活都在改善，但是整个社会阶层正在扩大&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;想要学会寻找合适的“度”，至少需要掌握两个不同的理念&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;一棵树可能很简单，但树木组成的森林非常复杂，而刺猬则以为只要他能理解树，就能解释森林&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;常识只是特别善于在事后“解释”事件，这种解释根本谈不上真正的理解&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;为了模仿而模仿，是最大不稳定因素，因为它让原本无关的人参与到事件之中，导致事态以爆炸的速度迅速扩大&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;经济智慧&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;经济学家的智慧在于问一句值不值得，哪怕这个东西在好，如果它的要价太高，那么我们应该不要，反过来说，哪怕要付出一个代价，只要换来东西的价值大，那就可以付出&lt;/li&gt;
  &lt;li&gt;边际分析是指你不用考虑总的效果，只要考虑做下一步的临界效果就行
    &lt;ul&gt;
      &lt;li&gt;经济学家的经验是边际效应常常递减，可能你投入的钱越来越多，但是效果越来越不明显？&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;养成新习惯需要先做不习惯的事情&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;懂行的政客从来不给选民上经济课，专门给选民讲故事&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;国家的利益：国家作为一个抽象概念，没有自己的利益，是国家中不同人群有各自不同的利益&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;高中根本的目的不是传授知识和培养人，而是把人分类&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;自控，是一个非常基本和可贵的素质&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;现代教育分为三个阶层&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;贫民家庭对教育的期待是培养工具，以找工作为目的&lt;/li&gt;
  &lt;li&gt;中产阶级对教育的期待是培养工艺品，以提升个人价值为目的&lt;/li&gt;
  &lt;li&gt;上层家庭对教育的期待是培养主人翁，以欣赏、选择和改变周围世界为目的&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;资本主义的本质就是把人变成工具，不是资本主义，是工业化时代生产分工的本质&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;数据分析的真正作用是能让好东西迅速流传开来，然后迅速灭亡&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;技术不仅仅对人类生活提供辅助性的帮助，直接改变人类的行为模式和社会制度，技术发展的大势决定天下大势&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;互联网是进攻武器还是防守武器？&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;信息极客的三个功夫&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;阅读学术论文&lt;/li&gt;
  &lt;li&gt;直接阅读原始数据&lt;/li&gt;
  &lt;li&gt;主动采集和分析数据&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;结论&quot;&gt;结论&lt;/h1&gt;

&lt;p&gt;知识本身不在值钱，但是不值钱不代表不重要，就像空气一样，不值钱但是很重要&lt;/p&gt;
</description>
        <pubDate>Tue, 05 May 2020 14:29:00 +0800</pubDate>
        <link>http://localhost:4000/2020/05/%E6%99%BA%E8%AF%86%E5%88%86%E5%AD%90/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/05/%E6%99%BA%E8%AF%86%E5%88%86%E5%AD%90/</guid>
        
        <category>社科</category>
        
        
      </item>
    
      <item>
        <title>极简GPB历史</title>
        <description>&lt;h1 id=&quot;简介&quot;&gt;简介&lt;/h1&gt;

&lt;p&gt;介绍GDP历史&lt;/p&gt;

&lt;h1 id=&quot;许多最终在民用领域发扬光大的新技术最初都是为了满足作战需求而研发的&quot;&gt;许多最终在民用领域发扬光大的新技术，最初都是为了满足作战需求而研发的&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;GDP是第二次世界大战众多发明之一&lt;/li&gt;
  &lt;li&gt;GDP被设计出来的目的
    &lt;ul&gt;
      &lt;li&gt;衡量在物资稀缺的情况下，经济中物质资源的使用情况和可获得性，尽管情况错综复杂，但对物质产品的测量还是非常简单、明确的&lt;/li&gt;
      &lt;li&gt;GDP现在不是，过去也从来没有打算要成为衡量福利的标准，它衡量的是生产&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;生活中经常出现的那样，失败的种子往往扎根于成功的本质中。&lt;/p&gt;

&lt;h1 id=&quot;只有在收入远高于食物住房和衣物支出时候人们才能超越谋生的艰辛去关心别的事情&quot;&gt;只有在收入远高于食物、住房和衣物支出时候，人们才能超越谋生的艰辛，去关心别的事情&lt;/h1&gt;

&lt;h1 id=&quot;希腊悲剧三大元素&quot;&gt;希腊悲剧三大元素&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;傲慢&lt;/li&gt;
  &lt;li&gt;愚蠢&lt;/li&gt;
  &lt;li&gt;毁灭&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;中国同时面临的问题&quot;&gt;中国同时面临的问题&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;人口快速老化&lt;/li&gt;
  &lt;li&gt;男性人口过剩&lt;/li&gt;
  &lt;li&gt;福利和养老的缺乏&lt;/li&gt;
  &lt;li&gt;房地产的泡沫&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;消费主义会让人上瘾&quot;&gt;消费主义会让人上瘾&lt;/h1&gt;

&lt;p&gt;大多数人对地位以及相对收入的关心超过对绝对收入水平的关心&lt;/p&gt;
</description>
        <pubDate>Tue, 05 May 2020 14:12:00 +0800</pubDate>
        <link>http://localhost:4000/2020/05/%E6%9E%81%E7%AE%80GPB%E5%8E%86%E5%8F%B2/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/05/%E6%9E%81%E7%AE%80GPB%E5%8E%86%E5%8F%B2/</guid>
        
        <category>经济-科普</category>
        
        
      </item>
    
      <item>
        <title>一件T恤的全球经济之旅</title>
        <description>&lt;h1 id=&quot;简介&quot;&gt;简介&lt;/h1&gt;

&lt;p&gt;这是从T恤的角度来描述经济的&lt;/p&gt;

&lt;h1 id=&quot;国际贸易流动的背后是消费的需求&quot;&gt;国际贸易流动的背后，是消费的需求&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;想要了解经济史上某一个事件在某一个地点和时间为何发生或为何没有发生的最有效的方法就是想想谁是受益者&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&quot;美国种植园&quot;&gt;美国种植园&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;通过奴隶制度，避开劳动市场风险&lt;/li&gt;
  &lt;li&gt;财产权、激励措施（管理）是必要体系&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;从环保的角度来看，能杀死植物的物质肯定不可能对咱们有益处&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&quot;棉花的进步&quot;&gt;棉花的进步&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;机械&lt;/li&gt;
  &lt;li&gt;化学药品&lt;/li&gt;
  &lt;li&gt;转基因技术&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;直觉告诉咱们廉价劳动力是一种优势，劳动力成本在人们别无选择的时候才会变得廉价&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;旅行者为当今世界各地的逐步同化感到惋惜&lt;/p&gt;

&lt;h1 id=&quot;惯性的原因&quot;&gt;惯性的原因&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;没有其他选择&lt;/li&gt;
  &lt;li&gt;缺乏经验&lt;/li&gt;
  &lt;li&gt;视野有限&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;结论&quot;&gt;结论&lt;/h1&gt;

&lt;p&gt;最好的经济政策并不有利于成就最佳的政治，同理，可证。&lt;/p&gt;
</description>
        <pubDate>Tue, 05 May 2020 14:12:00 +0800</pubDate>
        <link>http://localhost:4000/2020/05/%E4%B8%80%E4%BB%B6T%E6%81%A4%E7%9A%84%E5%85%A8%E7%90%83%E7%BB%8F%E6%B5%8E%E4%B9%8B%E6%97%85/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/05/%E4%B8%80%E4%BB%B6T%E6%81%A4%E7%9A%84%E5%85%A8%E7%90%83%E7%BB%8F%E6%B5%8E%E4%B9%8B%E6%97%85/</guid>
        
        <category>经济-科普</category>
        
        
      </item>
    
      <item>
        <title>从骰子到阿尔法狗-趣谈概率</title>
        <description>&lt;h1 id=&quot;简介&quot;&gt;简介&lt;/h1&gt;

&lt;p&gt;这本书是关于概率的，这其中关于信息量的统计是非常精彩的&lt;/p&gt;

&lt;h1 id=&quot;概率论本来就是从多个赌博游戏中滋生中&quot;&gt;概率论本来就是从多个赌博游戏中滋生中&lt;/h1&gt;

&lt;h1 id=&quot;墨菲定律&quot;&gt;墨菲定律&lt;/h1&gt;

&lt;p&gt;含义：凡事有可能会出错的，就一定会出错&lt;/p&gt;

&lt;p&gt;从下面的原因去理解：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;如果暂时没有出错，也只是时间的问题&lt;/li&gt;
  &lt;li&gt;大数定理体现类似的意思，当实验次数足够多时，事件发生的频率就是趋向它的概率&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;两种派别&quot;&gt;两种派别&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;频率学派
    &lt;ul&gt;
      &lt;li&gt;描述的是事物本体&lt;/li&gt;
      &lt;li&gt;把模型参数看成是固定&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;贝叶斯学派
    &lt;ul&gt;
      &lt;li&gt;描述的是观察者知识状态在新的观测发生后如何更新&lt;/li&gt;
      &lt;li&gt;通过新得到的证据不断更新你的信念，你能根据新的知识做出可信的判断，总会保留一定的不确定性&lt;/li&gt;
      &lt;li&gt;参数也看成随机变量，也符合某种分布&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;熵&quot;&gt;熵&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;熵只增不减，熵的增加意味着系统中的能量不断地贬值&lt;/li&gt;
  &lt;li&gt;熵最大就是事物可能的状态数最多，复杂程度最大&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;信息量的统计&quot;&gt;信息量的统计&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;英文和汉字&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;英文有26个字母，每一个字母出现的概率相等，信息量=-log(1/26) = 4.7.比特&lt;/li&gt;
  &lt;li&gt;汉字有2500个常用字，信息量=-log(1/2500)=11.3比特&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;所以一个汉字含有的信息比一个字母多的，也就是说很多的时候，一本英文书籍翻译成中文，它的页数变少&lt;/strong&gt;&lt;/p&gt;

</description>
        <pubDate>Tue, 05 May 2020 13:57:00 +0800</pubDate>
        <link>http://localhost:4000/2020/05/%E4%BB%8E%E9%AA%B0%E5%AD%90%E5%88%B0%E9%98%BF%E5%B0%94%E6%B3%95%E7%8B%97-%E8%B6%A3%E8%B0%88%E6%A6%82%E7%8E%87/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/05/%E4%BB%8E%E9%AA%B0%E5%AD%90%E5%88%B0%E9%98%BF%E5%B0%94%E6%B3%95%E7%8B%97-%E8%B6%A3%E8%B0%88%E6%A6%82%E7%8E%87/</guid>
        
        <category>数学-科普</category>
        
        
      </item>
    
      <item>
        <title>给投资新手的极简股票课</title>
        <description>&lt;h1 id=&quot;简介&quot;&gt;简介&lt;/h1&gt;

&lt;p&gt;这是看的一本书，做的一些笔记&lt;/p&gt;

&lt;h1 id=&quot;有钱的一个重要指标&quot;&gt;有钱的一个重要指标&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;被动收入&lt;/li&gt;
  &lt;li&gt;变富的过程，就是被动收入占比逐渐升高的过程&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;平凡的人&quot;&gt;平凡的人&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;安于现状，永远依赖工资收入&lt;/li&gt;
  &lt;li&gt;陷入怪圈，不管赚多少钱都不够用&lt;/li&gt;
  &lt;li&gt;根本没有幻想中的救世主&lt;/li&gt;
  &lt;li&gt;没有给子女留下任何遗产，甚至将压抑的人生传给下一代&lt;/li&gt;
  &lt;li&gt;唯一可复制的致富渠道：善用复利的力量&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;远离群体单独行动是违背我们的天性&quot;&gt;远离群体单独行动是违背我们的天性&lt;/h1&gt;

&lt;h1 id=&quot;投机渠道&quot;&gt;投机渠道&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;货币基金：让资金少的散户享受大额存单的高级待遇，收益自然就高&lt;/li&gt;
  &lt;li&gt;债券
    &lt;ul&gt;
      &lt;li&gt;一张“合同”硬性规定，到期还本付息&lt;/li&gt;
      &lt;li&gt;最重要的是评估利息，以及债券发行人的还款能力&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;富有的人害怕&quot;&gt;富有的人害怕&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;经济倒退&lt;/li&gt;
  &lt;li&gt;文明崩溃&lt;/li&gt;
  &lt;li&gt;战争&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;投资问题&quot;&gt;投资问题&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;什么时候买
    &lt;ul&gt;
      &lt;li&gt;差的股市行情
        &lt;ul&gt;
          &lt;li&gt;过去的一两年曾大幅度上涨&lt;/li&gt;
          &lt;li&gt;指数和个股的PE，PB都非常高，股息率则非常低&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;中国内陆的A股
        &lt;ul&gt;
          &lt;li&gt;上海：15PE，2PB，超过要提防&lt;/li&gt;
          &lt;li&gt;深圳：20PE，2.6PB，超过要提防&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;买什么
    &lt;ul&gt;
      &lt;li&gt;评价的标准
        &lt;ul&gt;
          &lt;li&gt;市盈率PE
            &lt;ul&gt;
              &lt;li&gt;市值除以净利润&lt;/li&gt;
              &lt;li&gt;值越低越好&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;市净率PB
            &lt;ul&gt;
              &lt;li&gt;市值除以当前净资产&lt;/li&gt;
              &lt;li&gt;一般是越高越好&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;股息率
            &lt;ul&gt;
              &lt;li&gt;年度分红金额除以股票价格&lt;/li&gt;
              &lt;li&gt;分红&lt;/li&gt;
              &lt;li&gt;以三年期限定金存利率作为判断标准，高于这个值算好，低于这个值较差&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;为啥投资术语这么复杂&quot;&gt;为啥投资术语这么复杂&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;本来概念很简单的东西，但是人类天生有把事物复杂化的倾向，这样可以竖起一道门槛，疑惑别人&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&quot;总结&quot;&gt;总结&lt;/h1&gt;

&lt;p&gt;集体的愚蠢是最没有成本的愚蠢，也是代价最高的愚蠢，要记住，当社会最后一个观望人也进入股市，家庭里最后一笔闲置资金也买成股票，哪里还有钱继续推动股票的继续上涨，剩下的可能只有一种暴跌&lt;/p&gt;

</description>
        <pubDate>Mon, 04 May 2020 20:17:00 +0800</pubDate>
        <link>http://localhost:4000/2020/05/%E7%BB%99%E6%8A%95%E8%B5%84%E6%96%B0%E6%89%8B%E7%9A%84%E6%9E%81%E7%AE%80%E8%82%A1%E7%A5%A8%E8%AF%BE/</link>
        <guid isPermaLink="true">http://localhost:4000/2020/05/%E7%BB%99%E6%8A%95%E8%B5%84%E6%96%B0%E6%89%8B%E7%9A%84%E6%9E%81%E7%AE%80%E8%82%A1%E7%A5%A8%E8%AF%BE/</guid>
        
        <category>经济</category>
        
        
      </item>
    
  </channel>
</rss>
