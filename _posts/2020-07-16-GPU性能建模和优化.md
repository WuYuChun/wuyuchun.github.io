[TOC]



# GPU性能建模和优化

## 前言

![](/images/posts/2020-07-17-10-55-37-GPU性能模型01.png)

面向吞吐量的并行处理器的解析模型。

GPU的每一个关键组件：（提供每一种的优化策略）

- 寄存器文件
- 计算单元（SPU、DPU、SFU）
- 缓存（L1、L2、只读、纹理、常量）
- 暂存器

分析四种并行性：

1. TLP（thread-level-parallelism)：线程并行性
2. ILP：指令并行性
3. DLP：数据并行性
4. MLP：内存级并行性

和片上缓存效应以及片外存储之间的相互作用

每一个线程的最优寄存器数，对最佳的GPU性能有一定的影响

> 如何解释和改善GPU的性能？

内存带宽的扩展仍远远落后于内核或浮点性能的扩展，这表明内存墙一直是收获GPU性能的主要挑战。

**问题**

- 如何理解GPU硬件和软件中的并行性？
- 给定一个应用程序，什么是可能存在性能瓶颈？
- 为什么那里出现这样的瓶颈？
- 什么样的优化可以缓解甚至消除瓶颈？
- 可以提高多少性能？

## 背景

### GPU的视图：

- GPU机器模型（体系结构）
- GPU执行模型（线程层次结构，并映射到硬件）
- GPU编程模型（即内核配置和编译)
- GPU评估模型（基准测试和性能分析工具）

### 存储结构：

![](/images/posts/2020-07-16-09-54-59-GPU性能优化模型0.png)

**由于尺寸较大，GPU寄存器由SRAM实现，出于吞吐量考虑，这些SRAM分为多个存储体。 因此，与CPU寄存器相比，GPU寄存器经历了较长的访问等待时间，并可能遭受潜在的存储体冲突**

**loca memory不是物理内存空间，而是全局内存的一部分（请参见下文）。 它的范围是线程专用的，与RF相同（请参见上表）。 当没有足够的寄存器来容纳所有必需的变量时（即寄存器溢出），或者在内核中声明了数组但编译器无法确定引用它们的确切索引时，**

 **与Local memory或global memory相比，share memory在芯片上具有更高的带宽和更短的访问延迟。 因此，CUDA编程指南强烈建议可以将global memory/local memory访问转移到share memory的优化。 为了获得更高的带宽，共享内存被划分为存储体，因此可以并行访问（类似于寄存器文件和L2缓存）。 但是，如果来自同一内存请求的两个地址位于同一存储区中，则会发生bank冲突并且必须序列化访问权限，严重降低了共享内存的性能。**

**常量内存用于存储在内核执行过程中不变的数据。 对于所有GPU产品来说，它都是64KB，并且是片外的。 与本地内存类似，它是全局内存的特殊部分。 但是，常量内存不是由L1 / L2缓存的，而是一个称为常量缓存的单独的缓存。 **

**纹理存储器或表面存储器也驻留在全局存储器中。 它由纹理高速缓存缓冲，以便仅在存在高速缓存未命中时才执行纹理获取或表面读取。 纹理缓存专门针对2D空间局部性进行了优化。**

### 缓存结构：

L1指令缓存

L1数据缓存：用于GPU的L1数据缓存1最早是在Fermi中引入的。 SM专用L1高速缓存与SM的共享内存共享相同的片上存储。 它们的相对大小是可重新配置的（在Fermi中为16/48或48/16 KB，在Kepler中为16 / 48、32 / 32或48/16 KB）。 L1高速缓存行为128B。 它缓存全局内存读取和本地内存访问（读取和写入），并且是非一致性的。 local memory通常用于寄存器溢出，函数调用和自动变量。 L1缓存在缓存对全局内存的访问时为只读，但在缓存对本地内存的访问时为可写。 

L2数据缓存：它为所有类型的内存访问提供服务（即全局，局部，常量和纹理），并且与主机CPU内存保持一致。 L2缓存是可读写的，并采用回写替换策略。 它是数据统一的重点，也是跨SM共享数据的好地方。 通常将L2高速缓存划分为存储体，每个存储体均用作片外存储通道（GDDR）的缓冲区。或HBM2-DRAM），以显着降低最终内存带宽需求。

### NOC

SM和L2 bank之间的互连网络（NOC）是纵横制网络。它允许多个SM和L2 bank之间同时通信，从而提供可观的NoC吞吐量。典型的交叉开关NoC封装了一个地址总线和两个数据总线。地址总线从SM到L2 bank是单向的；而两条数据总线在SM和L2 bank之间形成双向通道。这里，通信是点对点的。内存请求队列（MRQ）和存储体加载队列（BLQ）分别附加到每个SM和L2存储区。当从SM内部的LSU生成加载请求时，它将首先缓存在本地MRQ中，然后通过交叉开关NoC传递到目标BLQ。在BLQ中等待一段时间后，请求将由L2 bank处理。众所周知，纵横开关网络的同时连接成本很高。特别是，当访问请求是随机且混乱的时，会出现干扰，从而导致有效带宽的减少。



### GPU执行模型

![](/images/posts/2020-07-20-09-31-51-GPU性能模型和优化_02.png)

#### SIMT

在SM中，就调度，执行和访问缓存/内存而言，warp是基本单位。



### GPU编程模型：配置和编译



#### 在线编译

> 每一个环节的输出是什么

#### Just-in-Time (JIT) 编译

> 在线编译，适合各种GPU



### GPU评估模型：仿真、基准、测量



####  仿真

GPGPU-Sim 

[GPGPU-sim]: https://github.com/gpgpu-sim/gpgpu-sim_distribution



#### 基准



#### 测量工具



# 评估模型

最大化占用率可能会导致寄存器溢出和较低的缓存性能。

如果存在大量的指令级并行性，则可以在降低占用率的情况下获得更好的性能，



## 寄存器的优化

寻找最佳的每线程寄存器使用率以提供最佳性能成为GPU软件开发人员的重要问题。有效的寄存器使用管理也被认为是当前CUDA工具链中最大的遗留问题之一



## cache

限制峰值性能的一个关键问题是来自大量并发线程的大量（有时是不规则的）内存访问。这对存储系统的带宽和效率施加了巨大的压力。

