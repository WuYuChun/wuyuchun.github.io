[TOC]



# Improving the speed of neural networks on CPUs





## 内存的局部性

高性能计算的最基本原则是，一旦您触摸了给定的内存地址，该地址附近的附近内存就会被加载到处理器裸片上的各种缓存中。 这使得附近的数据可供CPU使用的速度比必须从内存中获取数据的速度快得多。 最直接的后果是，人们应该努力让自己的内心循环 任何数值计算走连续内存。



## 循环展开和并行累加器



```c++
//循环张开
c+=a[i]*b[i];
c+=a[i]*b[i]+a[i+1]*b[i+1]+a[i+2]*b[i+2]+a[i+3]*b[i*3];
```

```c++
//并行使用多个累加器，这为编译器提供了更多功能自由进行流水线操作并将其分布在浮点单元之间：
c0 += a[i]*b[i]
c1 += a[i+1]*b[i+1];
c2 += a[i+2]*b[i+2];
c3 += a[i+3]*b[i+3];
c = c0+c1+c2+c3;
```

> 使用该手段，提升了26%（论文中的实验数据）



## SIMD

SIMD指令是CPU上低级并行化的基本构建块。 这些指令对连续数据并行执行多项操作。

```c++
#include <iostream>
#include <xmmintrin.h>


int main() {
    /*使用MMX做以下向量的点积*/
    short in1[] = {1, 2, 3, 4};
    short in2[] = {2, 3, 4, 5};
    int out1;
    int out2;
    __m64 m1;    /* MMX支持64位整数的mm寄存器 */
    __m64 m2;    /* MMX操作需要使用mm寄存器 */
    __m128 m128; /* for SSEn only*/
    /*每次往mm寄存器装入两个short型的数，注意是两个*/
    m1 = _mm_cvtsi32_si64(((int*)in1)[0]);
    m2 = _mm_cvtsi32_si64(((int*)in2)[0]);
    /*一条指令进行4个16位整数的乘加*/
    /*生成两个32位整数*/
    m2  = _mm_madd_pi16(m1, m2);

    /*将低32位整数放入通用寄存器*/
    out1 =  _mm_cvtsi64_si32(m2);
    /*将高32位整数右移后，放入通用寄存器*/
    m2  = _mm_slli_pi32(m2, 32);
    out2 =  _mm_cvtsi64_si32(m2);
    /*清除MMX状态*/
    _mm_empty();
    /*将两个32位数相加，结果为8*/
    out1 += out2;
    printf("a: %d\n", out1);

    std::cout << "Hello, World!" << std::endl;
    return 0;
}

```

## SIMD的数据排布

数据排布的困难：

- 首先，SIMD指令通常在内存中16字节对齐的16字节块上运行得更快。16字节对齐 "意味着第一个字节的内存地址是16的倍数。因此，如果要处理的数据数组没有按照16字节对齐，性能将受到很大影响。在C语言中，可以通过将调用替换为用posix_memalign()来malloc()，如果使用标准模板库，则使用自定义分配器。
- 其次，由于每条指令都是在16个字节的块上操作，如果数据向量的大小不是16个字节的倍数，就必须处理边缘效应。最简单的解决方案是零填充：将每个大小为N的向量视为大小为((N+15)=16)的向量。∗ 16（整数算术），末尾加零。对于大多数线性运算，如标量乘积、求和、矩阵乘法，嵌入到这种较大的向量空间中是不变的，不会影响结果。

##　Floating-point SIMD and Intel SSE2

支持SSE2的Intel和AMD处理器提供了使用浮点SIMD算术执行乘加步骤的基本指令。



> Eigen是一个非常特别注重缓存优化的快速库。



## 定点化实现

我们使用8位量化将激活转换为无符号char，将中间层权重转换为有符号char，但偏差编码为32位int。输入层仍然是浮点数，这是一个例外，它可以更好地适应非概率输入的潜在更大动态范围。在我们的特定用例中，输入层比任何后续层都要小得多（440x2000），并且不会对整体速度产生太大的影响。将大部分网络量化为8位的重要好处之一是，网络的总内存占用空间因此缩小了3倍至4倍。

通过在每一层中获取最大权重并对其进行归一化以使其落在[-128; 127]范围。偏差按相同的比例缩放并线性量化为32位。每一层的矩阵乘法产生一个32位整数，然后将其快速近似地做成S型，然后映射为8位概率。



## SSE指令

SSE的全称是 Sreaming SIMD Extensions， 它是一组Intel CPU指令，用于像信号处理、科学计算或者3D图形计算一样的应用。其优势包括：更高分辨率的图像浏览和处理、高质量音频、MPEG2视频、同时MPEG2加解密；语音识别占用更少CPU资源；更高精度和更快响应速度。使用SSE指令集，主要是通过8个128-bit的寄存器：xmm0到xmm7 来完成的。**在Linux下可以使用cat /proc/cpuinfo来查看CPU支持哪些指令集。**  SSE的指令集是X86架构CPU特有的，对于ARM架构、MIPS架构等CPU是不支持的，所以使用了SSE指令集的程序，是不具备可移植标准的。