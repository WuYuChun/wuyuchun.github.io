# GPU优化小策略





## 内存访问的向量化

内存访问的数据类型可能会对带宽利用率产生重大影响。 因此，编译器首先检查内核函数内部的数据访问，以查看是否可以将它们分组为矢量类型的数据访问。由于不同的GPU在向量类型上对带宽利用的要求明显不同，因此编译器遵循不同的规则来调整向量化的积极性。在本文中，我们专注于CUDA和NVIDIA GPU，其中两个浮点数（即float2）的向量是首选数据类型，但相对于浮点数类型的带宽改进不到3％。因此，我们使用以下严格规则：如果对具有索引的同一数组进行一对访问：2 * idx + N和2 * idx + N + 1，其中N是偶数，则编译器将生成float2 变量f2的数组偏移量为idx + N / 2，并将原始数组访问替换为f2.x和f2.y。当实部存储在每个数据元素的虚部旁边时，他的规则本质上是为使用复数的应用程序设计的。 请注意，这种数据访问向量化比经典向量化更为简单。

对于AMD / ATI GPU，由于对带宽的影响更为深远，因此编译器更具侵略性，并且还将来自相邻线程的数据访问沿X方向分组为float2 / float4数据类型。数据访问矢量化的权衡是，如果矢量数据访问未合并（第3.2节），并且编译器通过共享内存将它们转换为合并的访问（第3.3节），则可能存在存储区冲突。 对于AMD / ATI GPU，矢量化的好处远远超过了共享内存库冲突带来的损失。 但是，对于NVIDIA GPU，矢量化的好处是有限的。 因此，编译器将跳过这些附加步骤以向量化数据访问。

## 检查内存合并

如第2节所述，GPGPU采用SPMD模型，并且单个线程中的线程在SIMD模式下执行内核功能。 因此，为了确定是否可以合并片外内存访问，我们需要针对不同的线程计算内核函数中每个内存访问的地址。 由于数组是科学和媒体处理中最常见的数据结构，因此我们考虑四种类型的数组索引以及这些索引的仿射变换：

1.常数索引：常数值用于数组索引，例如，“ a [idy] [i + 5]”中的常数整数“ 5”。

2.预定义索引：预定义数字（例如绝对线程ID，IDX，IDY和相对线程ID），Tidx（即threadIdx.x），tidy（即threadIdx.y）用作数组索引。 例如，“ a [idy] [i + 5]”中的“ idy”。

3.循环索引：循环迭代器变量用作数组索引，例如，图2a中“ b [i] [idx]”中的“ i”。

4.未解析的索引：使用数组索引，它不是前三种类型之一。 例如，间接访问“ a [x]”，其中“ x”是从内存加载的值。 由于我们的编译器无法确定此类索引的地址，因此我们仅跳过它们而无需检查它们是否可以合并。

在四种类型的索引中，与前两个索引相对应的地址对于给定线程是固定的。 但是，对于第三个，我们需要检查循环迭代器的不同值。 假设循环索引从S开始，且增量为Incr，那么我们需要检查前16个迭代中的索引地址：S，S + Incr，S + 2 * Incr到S + 15 * Incr。原因是，就地址是否为16的倍数而言，是否可以合并访问，对于其余的迭代重复相同的行为。

在确定内核函数中的数组索引的类型之后，对于每条内存访问指令，编译器都会从同一扭曲（即半扭曲）的16个连续线程中计算地址，以查看它们是否可以合并。 如第2节所述，如果我们假设数组类型为“ float”，则合并的访问将形成一个合并的段，该段从一个地址开始，该地址的值是64的倍数，大小为64个字节。在16个线程中的地址中，我们称最小的为“基地址”。 基地址与后续15个线程的地址之间的差异称为“偏移”。 为了满足合并要求，基址必须是64的倍数，而偏移量必须是1到15个字。 以下两个规则用于处理常见的数组访问。

对于多维数组的索引，例如'A [z] [y] [x]'，高阶维度的索引，例如'y'和'z'维度应保持相同 半经中的所有16个线程。否则，例如，如果在多维数组'A [] [idx] [0]中使用指向“ y”维度的索引中使用了预定义索引“ idx”（沿“ x”方向的线程id）  '，来自16个线程的访问将为'A [] [0] [0]'，'A [] [1] [0]'，'A [] [2] [0]'等，从而没有合并。

在内核函数中使用循环索引时，编译器将为循环迭代器的每个可能值计算基址和偏移量。例如，对于图2a中的地址“ a [idy] [i]”，当迭代器“ i”为0时，基地址为“＆a [idy] [0]”；  “ i”为1时为“＆a [idy] [1]”，以此类推。偏移量全为零，因为地址在同一半扭曲中对于不同的线程不会更改。由于基地址和偏移量均不满足该条件，因此数组访问“ a [idy] [i]”不会合并。 对于图2a中的数组访问“ b [i] [idx]”，当“ i”为0时，基地址为“＆b [0] [0]”。 如果“ i”为1，则为“＆b [1] [0]”，依此类推。偏移量从1个字到15个字。 因此，只要数组b的每一行都与16个字的倍数对齐，就合并数组访问“ b [i] [idx]”。 对于数组访问“ b [idx + i]”，尽管偏移量满足每个可能的“ i”的条件，但由于基地址并不总是16字的倍数，因此不是合并访问，例如“ b [  1]”（当“ i”为1时）。

## 将非强制访问转换为合并访问

在编译器分析了内核代码中的每个数组访问之后，编译器通过共享内存将非逐级访问转换为合并访问。 此处的观察结果是，对于每个非逐段内存访问指令，编译器可以从半扭曲确定包含非逐段内存访问所需数据的合并段。 然后，编译器将引入共享内存数组变量，插入语句（合并的内存访问）以初始化共享内存变量，并将原始的全局内存访问替换为共享内存访问。 线程块的大小也设置为16，以便每个线程块包含一半的翘曲。 还插入了“ syncthreads”功能，以确保正确的访问顺序。

对于使用常量或预定义索引的数组访问，此过程通常很简单。例如，非强制访问“ A [idy] [0]”，合并段为“ A [idy] [0:15]”。 编译器将插入共享内存数组变量“ sA [0:15]”，并使用“ A [idy] [tidx]”初始化“ sA [0:15]”，其中tidx是经线内的相对线程ID。 如果在多维数组的索引中使用“ idx”，则编译器可能会引入一个循环以加载所需的数据以进行半扭曲。
   例如，对于数组访问“ A [idx] [0]”，半扭曲所需的数据为“ A [（idx-tidx）+（0:15）] [0]”，其中“（（idx-  tidx）'提供每个线程块的起始地址，该地址与半扭曲的起始地址相同，因为每个线程块仅由图3组成。编译器生成的合并内核。
   （b）合并的mv内核（a）合并的mm内核（S0）表示（i = 0; i <w; i =（i + 16））{（S1）__shared__ float shared0 [16];  （S2）shared0 [（0 + tidx）] = a [idy] [（（i + tidx）+0）];  （S3）__syncthreads（）;  （S4）对于（int k = 0; k <16; k =（k + 1））{（S5）sum + = shared0 [（0 + k）] * b [（i + k）] [idx]）;  （S6）}（S7）__syncthreads（）;  （S8）}（S9）c [idy] [idx] =和；  （S0）for（i = 0; i <w; i =（i + 16））{（S1）__shared__ float shared2 [16];  （S2）__shared__ float shared1 [16] [17];  （S3）shared2 [（0 + tidx）] = b [i + tidx];  （S4）对于（l = 0; l <16; l =（l + 1））（S5）shared1 [（0 + 1）] [tidx] = a [（（（idx-tidx）+1）] [[  i + tidx）];  （S6）__syncthreads（）; 对于（int k = 0; k <16; k =（k + 1））{（S8）sum + =（shared1 [tidx] [k] * shared2 [k]）（S7）;  （S9）}（S10）__syncthreads（）;  （S11）}（S12）c [idx] =和； 此时翘曲一半。 包含所需数据的合并段为“ A [（idx-tidx）+（0:15）] [0:15]”。 在引入的16个迭代循环中，共享内存数组用“ A [（idx-tidx）+1] [tidx]”初始化，其中l是新引入的循环的迭代器。 从这些示例中可以看出，并非共享存储器中加载的所有数据都是有用的，编译器将执行数据重用分析（第3.4节）以确定此转换是否有益。 如果不是，则编译器将跳过此访问上的合并转换。 在特殊情况下，如果数组访问同时涉及“ idx”和“ idy”，例如“ A [idx] [idy]”，则编译器会分析交换“ idx”和“ idy”以使其合并的可行性。 此转换等效于CPU代码上的循环交换。

对于使用循环索引'A [m * i + n]'的数组访问，其中'i'是循环迭代器，m和n是常量，编译器将循环展开为16 /（GCD（m，16）） 如果m小于或等于8。
   如果m大于8，则由于不同迭代之间的有限重用，合并访问几乎没有好处。 然后，编译器将来自展开循环的访问分组为合并的循环。 例如，对于数组访问“ A [idy] [i]”（其中“ i”是循环迭代器），段“ A [idy] [0:15]”包含前16个迭代的所有必需数据。 编译器将循环展开16次，引入共享内存变量sA [0:15]，该变量用A [idy] [tidx + i]初始化（展开后，i的增量为16），并替换为'  A [idy] [i]'和'sA [i]'。

对于图2中的朴素内核，图3中显示了合并的版本。带有迭代器“ k”的内部循环是展开带有迭代器“ i”的外部循环的结果。 在图2a的幼稚内核中，未合并访问“ a [idy] [i]”，这导致如上所述的循环展开。 合并了“ b [i] [idx]”，由于展开了“ a [idy] [i]”，因此转换为“ b [（i + k）] [idx]”。 在图2b的mv内核中，访问“ a [idx] [i]”和“ b [i]”都没有合并。 将访问权“ b [i]”转换为合并的访问权涉及16次（= 16 / GCD（1,16））循环展开，在图3b中变为“ b [i + tidx]”。 对于访问“ a [idx] [i]”，引入了带有迭代器“ l”的循环，并将访问权转换为“ a [（idx-tidx）+ l] [i + tidx]”。 另外，编译器可以在共享存储器阵列中增加填充以免存储体冲突，并在输入数据阵列中增加填充以确保每个阵列的行大小是16个字的倍数，从而满足存储器合并的要求。

内存合并后，我们的编译器生成的内核代码具有以下特征：

1.每个线程块沿X方向具有16个连续的线程（即，仅半个扭曲），因为硬件需要16个线程来合并内存访问，并且它们通过共享内存相互通信。 在下一个优化阶段（第3.5节），将扩展每个线程块中的线程数，以确保每个线程块中有足够的线程。

2.全局内存加载语句有两种类型：（a）全局内存到共享内存（G2S）：这些语句从全局内存中读取数据并将其存储到共享内存中，例如图3a中的（S2）。  （b）全局存储器到寄存器（G2R）：语句从全局存储器中读取数据并将其保存到寄存器中。 例如，在图3a的（S5）中，全局存储器访问“ b [（i + k）[idx]”将数据加载到寄存器中。

## 数据依赖性和数据共享

在此步骤中，编译器将检测数据依赖性和数据共享。 这种分析类似于分析仿射数组访问以进行局部性优化和并行化的分析[1]。 由于我们的编译器已经通过将合并的段与每个全局内存访问相关联来强制执行存储器合并，因此编译器可以通过比较段的地址范围是否重叠来检测数据共享。 在我们研究的应用程序中，我们发现数据共享沿X或Y方向在相邻块之间最频繁地发生。因此，我们当前的编译器实现主要着眼于检查相邻线程块之间的数据共享以及沿X或Y方向具有固定步幅的线程块。

数据共享/重用信息还用于确定用于内存合并的代码转换是否有益。
   如第3.3节所述，共享内存用作临时存储以实现内存合并。 但是，共享存储器中的数据可能没有用，因为它们只是从片外存储器中加载以满足合并要求。 例如，编译器加载A [idy] [0:15]，以便将访问A [idy] [0]转换为合并的访问。 当前，我们的编译器采用一条简单的规则来检查是否需要转换访问权限：如果共享内存中已加载的数据没有重用，则不会进行转换。 更加精心设计的启发式算法可以通过比较共享访问和数据重用的次数来进一步对不同访问的代码转换进行排名，然后在共享内存用尽的情况下选择最有益的代码。 我们将调查作为未来的工作来完善我们的编译器框架。

## 线程/线程块合并以增强内存重用

在检测到线程块（主要是相邻块）之间存在数据共享之后，我们提出了两种新技术来增强数据共享，从而减少全局内存访问的数量：合并线程块和合并线程。 线程块合并确定每个线程块的工作量，而线程合并确定每个线程的工作量。 这两种技术的结合本质上是一种通过将细粒度的工作项聚合到线程和线程块中来实现循环平铺和展开的方法。 我们首先介绍这两种技术，然后讨论编译器如何优先于另一种。

当我们的编译器确定多个线程块共享一些公共数据时，它可以选择将它们合并为一个线程块，如图4所示。

为了说明合并线程块的过程，我们展示了编译器如何将沿X方向的两个相邻块合并为一个。 首先，编译器重新计算线程块内的线程ID信息（即tid）。 当沿X方向的两个线程块合并时，idx，idy和tidy保持不变，而tidx重新计算为（idx％（N * blockDim.x）），其中图4的N为2。 导致数据共享的语句，我们添加了控制流以确保全局内存数据仅被加载一次。 对于图3a中的矩阵乘法示例，来自两个相邻线程块的线程中的语句S2访问同一段。 因此，我们添加了一条'if（tidx <blockDim.x）'语句，以消除冗余的全局内存访问，如图5所示。第三，调整了线程块的大小（blockDim.x = 2 * blockDim.x）。

由于线程块合并确定了每个线程块的工作量，并且同一线程块中的所有线程都重复使用共享内存中的数据，因此它实质上实现了针对局部性和并行性优化的循环切片。

增强数据共享的另一种方法是将来自不同线程块的线程合并，将多个线程的工作负载合并为一个，如图6所示。与线程块合并相比，将这些线程合并为一个线程后，它们不仅可以共享 内存，还有寄存器文件中的寄存器。 此外，一些控制流语句和地址计算可以重复使用，从而进一步减少了总体指令数。 限制是增加的工作量通常需要更多数量的寄存器，这可能会减少可以容纳在硬件中的活动线程的数量。 从讨论中可以看出，线程合并实现了循环展开的效果。 请注意，线程合并还将多个线程块合并为一个，但不会增加每个线程块中的线程数。

为了说明合并线程的过程，我们展示了我们的编译器如何将沿Y方向的N个相邻块合并为一个。 首先，编译器重新计算线程ID信息。
   当我们沿Y方向合并来自两个线程块的线程时，沿X方向'idx'的绝对线程ID保持不变，而沿Y方向'idy'的线程ID将更改为idy * N，idy * N +  1，对于N个复制的语句，idy * N + 2…，idy * N +（N-1）。 线程块中的线程ID信息保持不变。 其次，对于导致数据共享的声明，我们只需要一个副本。 第三，对于控制流语句（例如循环），我们也只需要一个副本。 第四，对于其余的语句，包括数据声明，ALU计算语句和其他内存访问语句，我们将它们复制N次。 对于图5中的矩阵乘法示例，数组访问'b [（i + k）] [idx]'导致线程块之间沿Y方向共享数据（因为访问地址不依赖于'idy'  ）。 编译器使用线程合并沿Y方向合并32个相邻块，如图7所示。

## 线程合并和线程块合并之间的选择

如3.3节所述，编译器在内存合并后生成的代码具有两种类型的全局内存访问：全局到共享内存（G2S）和全局到寄存器（G2R）。 如果相邻块之间的数据共享是由于G2S访问引起的，则编译器更喜欢线程块合并以更好地利用共享内存。 当数据共享来自G2R访问时，由于寄存器的重用，编译器更喜欢合并来自相邻块的线程。 如果有许多G2R访问，这导致不同线程块之间的数据共享，则寄存器文件的大小不足以容纳所有重用的数据。 在这种情况下，将使用线程块合并，并引入共享内存变量来保存共享数据。 另外，如果一个块没有足够的线程，即使没有数据共享，也使用线程块合并而不是线程合并来增加块中的线程数。

## 数据预取

数据预取是一种将内存访问延迟与计算重叠的众所周知的技术。 为此，编译器在循环中分析内存访问，并使用临时变量为当前循环中的计算之前的下一次迭代预取数据。 图8中说明了该过程。插入预取之前的代码在图8a中，图8b显示了插入之后的代码。 除了临时变量之外，还添加了其他检查以确保预取访问不会生成不必要的内存访问。

数据预取代码的开销是由于临时变量而导致寄存器使用量的增加。 如果该寄存器可用于数据重用（例如，作为线程合并的结果），则编译器将跳过此优化。

## 消除分区露营

在此步骤中，编译器重新使用为线程/线程块合并而获得的地址访问模式，以查看它们是否导致分区驻留。 由于沿X方向的相邻线程块可能同时处于活动状态，因此编译器将重点放在涉及blockIdx.x或简称bidx的地址上。
 那些不涉及bidx的访问基于线程阻塞具有不同的bidy的假设，或者访问相同分区中的同一行（例如，A [0]），或者在不同时间访问相同的分区（例如，A [bidy] [0]）。 将在不同的时间执行）。
   我们的编译器遵循以下规则。

分区预占检测：如果数组访问涉及bidx，则编译器会检查两个相邻块（即，一个具有ID为bidx的块，另一个具有bidx + 1的块）的两次访问之间的地址跨度。 如果步幅是（分区大小*分区数）的倍数，则编译器将检测分区预占。
   例如，对于数组访问A [idx]，它等效于A [bidx * blockDimx + tidx]。 两个相邻块之间的跨度为blockDimx，其值然后确定是否存在分区冲突（即，对同一分区的两次并发访问）。

消除分区宿营：如果访问导致分区冲突，则根据线程块的组织方式，我们使用两种方法来消除分区冲突：

1.如果线程块以一维排列，则添加固定偏移量（分区宽度 * bidx），访问并更新循环范围以适应更改。 例如，在mv中，输出是向量。 因此，线程块是在一维中组织的。 如果A的宽度为a，则来自相邻线程块的访问A [idx] [i]（或合并版本A [[（（idx-tidx）+1]] [（i + tidx）]）将导致分区驻留。  （分区大小*分区数）的倍数，如图9a所示。 使用增加的偏移量，将访问模式更改为图9b，从而消除了分区驻留。
2.如果线程块以二维或二维的形式组织，我们将采用[12]中提出的对角线块重新排序，这实际上会改变分配给每个线程块的工作量（或切片）。 对角线映射规则是newbidy = bidx和newbidx =（bidx + bidy）％gridDim.x。