

[TOC]

> 这是读取的一篇paper 《CudaDMA: Optimizing GPU Memory Bandwidth via Warp Specialization》
>
> [cudaDMA]: https://github.com/lightsighter/CudaDMA

# CudaDMA：通过Warp专业化优化GPU内存带宽

## 简介

很多程序是收到“内存带宽”的限制

对于许多程序员而言，创建利用GPU的高性能应用程序最困难的部分是**管理计算强度和内存带宽之间的平衡**。 **有效地利用GPU计算资源和内存带宽对于实现峰值的每节点性能至关重要**。 该任务很复杂，因为程序员必须使用相同的并行线程层次结构来执行计算和内存之间的数据传输。 该模型适用于以下情况：传输的数据的大小和维度在几何上类似于线程层次结构的大小和维度。 但是，对于许多应用程序，有足够的差异为程序员带来困难。

在先前的加速器中，例如单元宽带引擎和Imagine流处理器，通过使用**异步硬件DMA引擎解决了在片上和片外存储器之间移动数据的问题。** 这些系统将数据移动的责任委托给了硬件，从而使程序员能够集中精力优化正在执行的计算。

CudaDMA，这是一种可扩展的API，用于有效管理GPU的片上和片外存储器之间的数据传输。 CudaDMA使程序员能够将数据的大小和维度与计算的大小和维度解耦，从而提高了可编程性和性能。



## cuda的基本知识

各种关于cuda的基本知识。

对于GPU编程的挑战：

1. 如何设置warp中大小与需要获取的数据模式是匹配的？
2. 性能的问题

对应用程序性能进行分类的一种方法：

- 统计计算与内存比率

### 计算瓶颈

有三个常见的因素与片外存储器和片内存储器之间的数据传输有关，它们可能会限制指令发布带宽，并阻止充分利用GPU的所有计算资源。

- 许多长延时内存访问。如果足够多的长延时内存访问填满了内存系统的缓冲区，那么由于SMs的顺序性，warp的指令流就会停滞，使独立的计算指令无法发出。
- 粗粒度同步。使用粗粒度壁垒意味着CTA内的所有线程必须始终等待最慢的warp完成执行，然后才能继续在所有warp上执行，即使可以执行独立的工作。
- 数据访问模式。访问与CTA大小和维度不同的数据将需要有条件的分支，这可能会导致在访问共享内存时出现warp内分歧和bank冲突。

### 内存瓶颈

GPU内存系统被设计为支持许多并行负载和存储同时飞行。同时发出多个内存访问，并允许内存系统并行处理它们，被称为内存级并行（MLP）。

- 指令问题。如果一个warp的指令流由于计算资源被过度占用而停滞，那么独立的内存操作就会被阻止发出。
- 数据访问模式。访问与CTA大小和维度足够不同的数据会阻止内存操作的凝聚，这将导致序列化。这种效应严重降低了GPU实现的MLP。

### 小节

对这些问题的关键性见解，也是CudaDMA的动机，就是这两个领域的瓶颈是什么？耦合。这种纠缠的根本原因是CUDA编程模型鼓励的要求，即 CTA的线程同时执行内存访问和计算。通过创建专门的warp来执行独立的计算和内存操作，我们可以区分出 影响内存性能的问题，从那些 影响计算性能。通过对问题的解耦。我们消除了耦合，使程序员能够做到 孤立地解决平衡计算与内存比应用中的性能瓶颈。



## CudaDMA API

CudaDMA库提供了片上共享存储器和片外全局存储器之间移动数据的基础。该库的API的基本假设是，对于许多算法来说。最高效的传输实现是将一个线程块划分为不同的线程子集。只要这个分割是在warp粒度上进行的，不存在分化的性能惩罚。我们把这种分化技术称为warp特化。warp特化之前已经被用于在GPU上高效地并行实现排序算法。CudaDMA将这一技术封装到一个库中，使其普遍适用于更广泛的应用工作负载。

使用CudaDMA可以将线程分配到两类warp中。DMA-warp专门负责在全局内存和共享内存之间传输数据。计算经通过处理已传输到片上内存的数据来执行实际计算。**该API旨在帮助程序员对其warp进行专门化，明确哪些代码将由计算经线执行，哪些代码将由DMA经线执行。**

```c++
class cudaDMA {
__device__ cudaDMA (
const int dmaID ,
const int num_dma_threads ,
const int num_compute_threads ,
const int dma_threadIdx_start );
__device__ void execute_dma (
void * src_ptr ,
void * dst_ptr );
__device__ bool owns_this_thread ();
__device__ void start_async_dma ();
__device__ void wait_for_dma_start ();
__device__ void finish_async_dma ();
__device__ void wait_for_dma_finish ();
};
```

## 关于cudaDMA的案例

> 通过SGEMV的方式验证一下



## cudaDMA的基准测试

优化GPU内核的性能主要是管理受限的资源，如寄存器、共享内存、指令发布槽和内存带宽。Warp specialization允许CTA中的线程子集为特定目的调整其行为，从而更有效地消耗受限资源。我们有几种技术与经纬特化相结合来节约资源。

1. 指针运算。CudaDMA API允许将指针算术从内部循环中提升到构造函数中，这允许我们预先计算偏移量，并节省整数算术发行槽。通过减少所需的中间时序数
   对于指针运算，我们也可以保存注册表
2. 模板参数。虽然出于可编程性的原因，我们避免使用模板参数的精确值，但我们确实使用它们来为CudaDMA类的参数设置界限。模板参数使编译器能够执行恒定的折叠，节省整数算术和寄存器。
3. 利用用MLP：DMAwarp向量数据类型（即float4）的加载和存储，以充分饱和内存带宽。这种优化还可以节省内存指令发布槽，使DMA翘曲能够利用更大的应用MLP

.............

**使用CudaDMA编写代码的最简单方法是为每个要执行的传输分配一个单独的缓冲区。并为每个缓冲区关联一个cudaDMA对象。我们将 这种方法被称为单一缓冲，因为有一个单一的缓冲区，用于由一组DMA执行的每个传输。**

