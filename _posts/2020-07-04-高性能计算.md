[TOC]



# 简介

本书的目的一直是向新的程序员和科学家传授有关高性能计算的基础知识。

> 每瓦浮点运算竞争

本书旨在作为对高性能计算的简单介绍和概述。 这是一个有趣的领域，随着我们对最普通的个人计算机提出更高的要求，这一领域将变得越来越重要。 在高性能计算机领域，总是在单CPU性能和多处理器系统性能之间进行权衡。 多处理器系统通常更昂贵且难以编程（除非您有这本书）。

**这本书讲解的比较浅薄，都是一些基本性的概念**

# 介绍高性能计算

> 为什么要关心性能？

随着这些新型个人计算机的峰值速度的提高，这些计算机将遇到超级计算机上通常存在的所有性能挑战。虽然并非所有个人工作站用户都需要了解高性能计算的内在细节，但是对这些系统进行编程以实现最佳性能的人员将受益于对这些最新高性能系统的优缺点的了解。

高性能计算运行着各种各样的系统，从我们的台式计算机到大型并行处理系统。 由于大多数高性能系统都基于**精简指令集计算机（RISC）处理器**，因此将一种类型的系统上学到的许多技术转移到另一种系统上。

这些系统有两个方面。 一种类型是使用消息传递进行编程的。 这些系统不是使用标准的局域网，而是通过专有的，可扩展的，高带宽，低延迟的互连连接的（对于市场营销而言，这是怎么回事？）。 由于高性能的互连，这些系统可以扩展到成千上万的处理器，同时将花费（浪费）的执行开销通信的时间降至最低。

**高性能计算的研究是重新审视计算机体系结构的绝xuanz好机会。 一旦我们开始着手从计算机系统中获取性能的最后一点，我们就会变得更加有动力去充分理解对系统性能有直接影响的计算机体系结构的各个方面。**



# 现代计算模型



## 内存

在整个晚上的大部分时间里，当您尝试使用烙铁和瑞士军刀将500 MHz处理器调整为适用于Intel 8088插槽，你会觉得怎么样？就像前一天晚上回到中世纪，将喷气发动机装在马上一样。

**即使可以以极快的速度加快处理器的计算速度，您仍然必须将数据和指令加载到存储器中并从中存储数据和指令。 当今的处理器继续以微不足道的速度接近于快速处理。 内存性能的增长速度要慢得多（内存以极快的速度需要花费更长的时间）。** 高性能计算中许多有趣的问题都占用大量内存。 随着计算机变得越来越快，它们倾向于解决的问题的规模也随之增加。 问题在于，当您想高速解决这些问题时，您需要一个大型的内存系统，但同时又要面对很大的挑战。 

一个对内存的排列方式和详细信息有所了解的编译器缓存可以在一定程度上优化其使用。 优化的另一个地方是用户应用程序，我们将在本书的后面看到。 良好的内存访问模式将与系统组件配合而不是与之对抗。

> 我们将研究数据模式和指令访问方式如何影响您的整体运行时间，尤其是随着CPU速度的提高

DRAM和SRAM的技术：动态随机存取存储器（DRAM）和静态随机存取存储器（SRAM）。 术语随机意味着您可以按任何顺序寻址存储位置。 这是为了将随机存取与串行存储器区分开来，在串行存储器中，您必须单步执行所有插入的位置才能到达您感兴趣的特定位置。非随机存储介质的一个示例是磁带。 术语“动态”和“静态”与存储单元设计中使用的技术有关。 DRAM是基于电荷的设备，其中每个位都由存储在非常小的电容器中的电荷表示。 电荷可能泄漏到时间很短，因此必须不断刷新系统以防止数据丢失。 读取DRAM中的位的动作也会释放该位，要求对其进行刷新。 刷新时无法读取DRAM中的存储位。SRAM基于门，每个位存储在四个至六个相连的晶体管中。 SRAM存储器只要有功率就可以保留其数据，而无需任何形式的数据刷新。

> SRAM和DRAM之间的选择

### 访问时间

- 访问时间：是指从启动一次存储器操作到完成该操作所经历的时间。具体讲，从一次读操作命令发出到该指令完成，将数据读入数据缓冲寄存器为止所经历的时间 。
- 存取周期：指对存储器进行连续两次存取操作所需要的最小时间间隔

例如，如果您要求访问时间为50 ns的DRAM芯片中的数据，则可能需要100 ns才能从同一芯片中请求更多数据。 这是因为芯片必须从先前的访问内部恢复。 此外，当您从DRAM芯片顺序检索数据时，某些技术会提高性能。 在这些芯片上，紧接在先前访问的数据之后的数据可能会以10 ns的速度被访问。

仅使用SRAM来制造具有足够存储空间的廉价系统也是不切实际的。

**解决方案是使用处理器寄存器，一到三个级别的SRAM高速缓存，DRAM主存储器以及存储在磁盘等介质上的虚拟存储器来分层存储。 **

### 寄存器

目的是尽可能将操作数保留在寄存器中。

```c++
X = G * 2.41 + A / W - W * M;
```

需要保留中间结果在寄存器中，这样能省下加载内存的时间。

### 缓存

高速缓存是**少量的SRAM**，用于存储内存内容的子集。

![](/images/posts/2020-07-06-09-23-30-高性能计算-cache-01.png)

> 多处理器系统，如何维持cache的一致性

#### 缓存的组织

将内存位置与高速缓存行配对的过程称为映射。 当然，由于缓存小于主内存，因此必须为不同的内存位置共享相同的缓存行。 在高速缓存中，每条高速缓存行都有一条记录，表示它代表的内存地址（称为标记），以及上次使用的时间。 标签用于跟踪在特定高速缓存行中存储的内存区域。

##### 直接链接

**0k\4k\8k\12k\16k都映射到同一个cache line中。**

![](/images/posts/2020-07-06-09-40-08-高性能计算-cache-02.png)

##### 完成链接

> 这里直接映射到cache

##### 集合关联

- [ ] 这里分为2路，4路等情况链接

#### 指令缓存

指令缓存和数据缓存如何区分？两者之间有任何的联系？

- [ ] 哈佛结构

同样，由于大多数程序的顺序性质，指令通常具有极高的引用局部性。 因为指令高速缓存不必特别大才能有效，所以典型的体系结构是具有用于指令和数据的单独的L1高速缓存，并具有组合的L2高速缓存。

### 虚拟内存

虚拟内存的好处

#### 页表

每一个进程都有几个与之关联的页表。

![](/images/posts/2020-07-06-10-13-53-高性能计算-page_table.png)

通过页表进行地址转换非常复杂。

TLB

## 提高内存性能

**内存系统性能的两个属性通常是带宽和延迟。**

通常，供应商提供的峰值内存带宽是**数据缓存和处理器之间的速度.**

### 大的cache

![](/images/posts/2020-07-06-10-35-10-高性能计算-cache-04.png)



### winder memory sysytem

我们可以通过将存储系统的宽度增加到高速缓存行的长度来提高存储系统的性能，这时我们可以在一个存储周期内将整个行都存储起来。

更大的内存系统的缺点是，DRAM必须成倍增加。 

### 绕过cache

直接使用DMA

因此，供应商必须在其商品系统中添加更多这些存储系统功能，以在**处理器和存储系统速度之间保持平衡。**

### 交错和流水线存储系统

使用指令流水来增加访问存储

### 用软件来管理cache

**预取**:预取指令的操作与标准加载指令的操作相同，除了处理器不会在指令完成之前等待缓存ll结束。 这个想法是在计算之前预取足够多的数据，以便在实际计算发生时将数据准备好在缓存中。 

> post-RISC architecture？这个是什么架构呢？

### 动态RAM技术趋势

- Fast page mode DRAM
- Extended data out RAM (EDO RAM)
- Synchronous DRAM (SDRAM)
- RAMBUS
- Cached DRAM (CDRAM)



## 浮点数

> 计算机中的数值分析？如何精确的进行浮点运算？

### 使用Guard Digits 进行提供准确度

> 这里是如何使用Guard Digits来进行的呢？

这里如何保证计算的准确度？IEEE754



































# 编程和调试软件



## 编译器的作用

编译器的优化目标是将高级语言有效地翻译成最快的机器语言，以准确表示高级语言源。

编译器优化后的目标文件可能比未优化的文件要大。

>  编译器产生的原因

编译器编译c/c++的时候，遇到指针的问题在于，只有在执行时，才知道指针操作的效果。指针的值从内存中加载。 一旦优化编译器看到一个指针，它不能对编译时指针操作的效果做任何假设。 它必须产生保守（优化程度较低）的代码，其在机器代码中所做的操作与高级语言描述。

![](/images/posts/2020-07-08-09-37-28-高性能计算-编译器01.png)

这是最基本的编译器优化的过程

高级语言------编译（中间表达--优化）---->产生符合机器的代码

深度学习网络-------编译（中间表达--优化）----->产生符合机器的机器算子？

### 优化等级

-03

### 优化基本技术

- 消除计算
- 折叠
- 死代码去除
- Strength Reduction
- 重变量命名



## 耗时和性能

> 测量耗时以及整体性能，使用各种工具去评估各种数据



## 消除杂乱

代码杂乱导致编译器不好优化

杂乱的原因：

- Things that contribute to overhead
- Things that restrict compiler ffexibility

## 循环优化

- 循环展开
- 嵌套循环优化
- 循环交换
- 内存参考优化
- 封锁
- 核心解决方案

内存引用和操作计算的比率是一个关键的指标

**操作计数是一种简单的方法，可以估算循环的要求与机器性能的对应程度。 对于许多循环，通常会发现以内存引用为主的循环的性能， 这表明内存引用调整非常重要。**

循环张开的好处：

1. 每次迭代执行更多的计算
2. 每个循环执行的循环末端更少。 展开还显着减少了分支的总数，并为处理器提供了分支之间更多的指令（即，它增加了基本块的大小）

指令重排缓冲区

循环中含有子程序调用

### 内存访问模式

> 我们该如何重组内存来提高性能？

内外循环交换，导致按照顺序读取内存。



# 共享内存并行处理器

## 了解并行性

并行的粒度：

- 一个bit，一个bit的相加
- 指令并行（指令流水）
- 在两个标量处理器中，可以并行执行整数加和浮点数加的指令
- 放在多个CPU中
- 放在多个主机中

不同级别的并行粒度并不会冲突

探究一个算法运行多块的策略：

使用一个“无限”的CPU运行算法，分析耗时。

### 依赖



#### 控制依赖

> 什么是控制依赖呢？



#### 数据依赖

数据依赖的分类：

- 流程依赖
- 反向依赖
- 结果依赖

#### DAG

> DAG：directed acyclic graph，即有向无环图

**如何使用DAG来分析依赖关系？**

## 共享内存多处理器

这些处理器也被称为统一内存访问（也称为UMA）系统。

对称处理器

### 对cache的影响

cache的高命中率会减少内存总线的带宽

![](/images/posts/2020-07-14-08-47-33-高性能计算-对称处理器cache0.png)

以下用一个共享变量来说明对称处理器的一些问题

![](/images/posts/2020-07-14-08-50-56-高性能计算-chachel02.png)

>  缓存一致性协议？

### cache的状态

> 这里可以查看《对称处理器对unix的影响》这本书

- 修改
- 独占
- 共享
- 空/无效

> mesi协议

## 共享内存多处理器编程

- 操作系统如何支持多处理器呢？
- 用户态多线程呢？
- 操作系统如何支持多线程呢？

进程和多线程是如何在多处理器上进行运行呢？

多线程会遇到的问题：

- Fork-join (or create-join) programming
-  Synchronization using a critical section with a lock, semaphore, or mutex
-  Barriers

使用多个处理器的耗时：

![](/images/posts/2020-07-14-09-29-26-高性能计算-cache3.png)



对多处理器的耗时分布曲线图，不是越多处理器，就越多很好

![](/images/posts/2020-07-14 09-30-55-高性能计算-cache4.png)



#  可扩展的并行处理



##  语言支持性能 

编程语言天然不支持并行，因为是线性执行（顺序执行）





##  消息传递环境 

两种用于并行的消息：

- PVM（parallel virtual machine)
- MPI（message passing interface）

PVM的缺点：

- 需要打包步骤与发送步骤分开
- 它设计为在异构环境中工作可能会产生一些开销的事实
- 它不会自动执行诸如几何计算之类的常见任务

MPI的特性：

- communicators
- topologies
- communication modes
- sing-call collectve operations



# 附录

##  附录C：高性能微处理器 

介绍CISC和RISC指令集的体系结构以及它们之间的区别。

>  为什么现在RISC很少有用到的？

强大的指令节省了内存和时间。强大的指令节省了内存和时间。



##  附录B：看汇编语言 

