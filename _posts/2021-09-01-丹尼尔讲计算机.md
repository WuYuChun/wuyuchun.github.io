# 丹尼尔讲计算机

本书提出两个可能的方向：

- 量子计算
- 计算机能像生物进化过程那样实现自我设计

计算机最引人称道的一点是：**其本质远胜于技术**

计算机的本质基于几条基本原则：

- 功能抽象原理：奠定因果关系层次结构
- 通用计算机原理，即所有的计算机都属于同一种类型，更确切地说，所有类型的计算机在能做和不能做哪些事上是类似的。
- 存在一种全新的计算机设计和编程方式，它并不基于标准的工程设计方式。

*第一条原则会导致系统带有一定程度的脆弱性和低效性，这个缺点与信息处理器的基础性缺陷没有关系，而是层次设计方式的一个缺陷*

二进制的概念：最新的“非同小可的差异”将所有信号分成截然不同的两类。

数字技术的真正精髓在于：**每一级都能将信号复原并保持在完善的状态，目前为止，这是我们所知道的控制复杂系统的唯一方法**

**布尔逻辑块**和**有限状态机**是计算机硬件的通用构件，编程语言是计算软件的通用构件

针对于RISC和CISC指令集，不会影响到程序员的设计，因为任意一种合理的指令集都可以模拟出任何其他的指令集。

具有哲学意味的主题：

- 图灵机
  - 通用性原理产生的一个结果：两台计算机在能力方面唯一重要区别在于他们的运算速度和内存大小。
  - 只要有足够的时间和存储空间，任何一种通用计算机都能完成所有物理计算装置所能完成的计算任务。它暗示我们在通用计算上进行合理的编程，就有可能模拟出人类大脑的功能。
- 可计算性
- 混沌系统
- 哥德尔的不完备定理
- 量子计算机
  - 若想计算结果越准确，所用的时间越长，然而一杯水中的每一个分子几乎可以瞬间完成此运算，为何单个分子的运算速度比数字计算机快得多？
  - 量子纠缠的丧失现象被称为“脱散”，可能会成为量子计算机的致命弱点

算法：是一种失效安全机制，能确保达成既定目标。

传输和存储是同一个事物不同方案：**传输将一条信息从一个地点发送到另一个地点，而存储将一条信息从一个时刻“发送”到另一个时刻**

所有的压缩方法都利用了数据的规律性。

信息度量的结论：**一个二进制模式的信息量等同于能够生成这些二进制位的最短计算机程序的长度**

技术的发展史表明：人类的考虑并非始终万无一失，惨痛的失败通常发生在意料之外。

**处理器和存储器之间的数据流速度是顺序计算机的瓶颈所在，其根本问题在于，存储器在每一个指令周期内只能访问单个地址**

第三个低效率问题的根本原因：如何将任务均衡地分配给不同的处理器。

安达尔定理：总有一部分计算具有内在的顺序性，每一次只能由单个处理器完成，即使只有10%的计算任务，他们实质上也具有内在的顺序性，无论任何加速剩余的90%的并行计算任务，整体计算速度的提升比例永不会超过10倍。

**安道尔定律的缺陷？**

有效使用并行计算机的方式：让每一个处理器执行相似的任务，但使用不同部分的数据。

大多数计算任务能被分解成为并行处理的子问题，原因之一：**大多数计算都基于物理世界的模型，这些计算可以并行的方式进行，因为物理世界的运行方式也是并行的**

预言：**互联网发展到最后，一定会将电话、汽车以及家用电器都嵌入到计算机内**

任何基于反馈机制的系统都需要如下三类信息：

1. 什么是理想状态（目标）
2. 当前状态和理想状态之间有什么差异（误差）
3. 采取什么样的行动会减少当前状态和理想状态之间的差异（响应）

感知系统只能通过犯错来学习，这是所有基于反馈的自学习系统的共同特点。假设预期的权重（利用该权重即可准确地完成任务）确实存在，那么只有给予足够的训练，这个反馈过程将始终收敛于正确的权重。

意味着不能讲只能视为一种按层次结构设计的机器，指望通过分解和分析便能理解。

**工程设计方法的致命弱点在于，它依赖于严密的层级结构，这必定会导致机器缺乏灵活性，具有层级结构的系统容易发生灾难性故障，从这个角度来说，他们是脆弱的，从本质上说，工程产品是脆弱的，因为工程系统中的米一个子系统都必须符合规定它与其他子系统之间的一种协议，如果有一个子系统违反了该协议，则系统设计依赖的假设便不再有效，系统就会以一种不可预测的方式崩溃。**

如果系统非常复杂，就没有人能够掌握系统的全貌，这种情况带来的后果，弄错接口以及设计的低效性会导致许多错误，而随着系统变得越来越复杂，接口问题会变得更加严重。

上述的问题并不是机器或者软件自身固有的缺陷，它们是工程设计过程中产生的缺陷。

大脑和计算机之间的可靠性对比说明了进化产物和工程设计产品之间的差别。

**关键的一点在于，将分层体系设计的复杂性问题转移到计算机的组合能力上，从本质上说，模拟进化过程是一种启发式搜索技术啊，它可以搜索可能的设计空间，而用于搜索此空间的启发式方法：尝试与已有的最佳设计相似的设计方案，或者结合两个成功的设计方案的元素。**

