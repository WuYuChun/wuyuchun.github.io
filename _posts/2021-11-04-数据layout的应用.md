# c++ layout的使用

[struct_layout工具的使用](https://marketplace.visualstudio.com/items?itemName=RamonViladomat.StructLayout)

对于c/c++的数据布局，在内存中，究竟是一个怎么样的情况。然后就想看看有没有工具来实现这个布局的显示。发现在vs2019中有一个StructLyaout的工具，顺便也检验一下自己的知识。

其中涉及有一个比较重要的概念，叫内存对齐。为什么会出现内存对齐？

现代计算机中内存空间都是按照 byte 划分的，从理论上讲似乎对任何类型的变量的访问可以从任何地址开始，但是实际的计算机系统对基本类型数据在内存中存放的位置有限制，它们会要求**这些数据的首地址的值是某个数k（通常它为4或8）的倍数**，这就是所谓的内存对齐。

尽管内存是以字节为单位，但是大部分处理器并不是按字节块来存取内存的.它一般会以双字节,四字节,8字节,16字节甚至32字节为单位来存取内存，我们将上述这些存取单位称为**内存存取粒度**.

-------

现在考虑**4字节存取粒度**的处理器取int类型变量（32位系统），该处理器只能从地址为4的倍数的内存开始读取数据。

假如没有内存对齐机制，数据可以任意存放，现在一个int变量存放在从地址1开始的联系四个字节地址中，该处理器去取数据时，要先从0地址开始读取第一个4字节块,剔除不想要的字节（0地址）,然后从地址4开始读取下一个4字节块,同样剔除不要的数据（5，6，7地址）,最后留下的两块数据合并放入寄存器.这需要做很多工作.

![](/images/posts/2021-11-04-数据layout的应用.png)

若是有了内存对齐机制，int的变量放到0地址开始，就可以一次性读取数据。

### 内存对齐的原则

每个特定平台上的编译器都有自己的默认“对齐系数”（也叫对齐模数）。gcc中默认#pragma pack(4)，可以通过预编译命令#pragma pack(n)，n = 1,2,4,8,16来改变这一系数。

有效对其值：是给定值#pragma pack(n)和结构体中最长数据类型长度中较小的那个。有效对齐值也叫**对齐单位**。

对齐原则：

1. 结构体第一个成员的**偏移量（offset）**为0，以后每个成员相对于结构体首地址的 offset 都是**该成员大小与有效对齐值中较小那个**的整数倍，如有需要编译器会在成员之间加上填充字节。
2.  **结构体的总大小**为 有效对齐值 的**整数倍**，如有需要编译器会在最末一个成员之后加上填充字节。

### 例子

```c++
#include<stdio.h>
struct
{
    int i;
    char c1;
    char c2;
}x1;

struct {
    char c1;
    int i;
    char c2;
}x2;

struct {
    char c1;
    char c2;
    int i;
}x3;

int main()
{
    printf("%d\n", sizeof(x1));  // 输出8
    printf("%d\n", sizeof(x2));  // 输出12
    printf("%d\n", sizeof(x3));  // 输出8
    return 0;
}
```

> 测试环境为win10 vs2019

![](/images/posts/2021-11-04-数据layout的应用01.PNG)

![](/images/posts/2021-11-04-数据layout的应用02.PNG)

![](/images/posts/2021-11-04-数据layout的应用03.PNG)

从这三个图中可以看出来，对于内存的浪费，分别是25%-> 50%-> 15%，若是嵌入式设备上，这种浪费内存空间是非常可怕的。

### package的使用

数据打包，是指对数据内存排布进行一种设定。

例如，pragma pack(n)

例如设置 pragma pack（1）

![](/images/posts/2021-11-04-数据layout的应用04.PNG)

![](..\images\posts\2021-11-04-数据layout的应用05.PNG)

也就是通过 pack(n)的数量来改善数据内存的排布

## class的数据排布

针对于C++的类数据排布可以查看《深入探索C++对象模型》

**C++在struct(class)上的布局成本和C语言布局成本发生不同的情况出现在virtural。**

也就是说，一个没有virtural function，virtural base class的C++ struct(class)和C struct的内存布局是一样的。C ++ struct(class)里面的 function并不会出现在类的实例中，构造函数，析构函数，操作符重载只要不含virtural就和只含有这几个基本数据的C struct是一样的（这里有个条件，C++ struct里的静态数据成员不会出现在实例中，并且没有考虑嵌套其他struct的情况，只考虑了数据成员为基本数据类型的情况）。

```c++
class class_tmp {
public:
    class_tmp();
    ~class_tmp();
    int add(int x, int y);
protected:
    virtual std::ostream& print(std::ostream& os) const;

private:
    int i;
    char c1;
    char c2;
};

```

![](/images/posts/2021-11-04-数据layout的应用06.PNG)



**数据成员的那一部分和C struct的规则是一致的，所以这一部分参照C struct的内存布局即可，**

**没有虚拟方法的C++ struct最后是不含有vptr的，含有虚拟方法的struct才会加上这一项。**

### 关于组合





### 关于继承

```c++
class class_tmp {
public:
    class_tmp();
    ~class_tmp();
    int add(int x, int y);
protected:
    virtual std::ostream& print(std::ostream& os) const;

private:
    int i;
    char c1;
    char c2;
};

class class_add :public  class_tmp
{
public:
    class_add();
    ~class_add();

private:
    std::string m_str_;

};
```



![](/images/posts/2021-11-04-数据layout的应用07.PNG)




## 序列化数据



## 深度学习中关于内存数据排布的

[数据排布](https://oneapi-src.github.io/oneDNN/dev_guide_understanding_memory_formats.html)

大多数计算都是关于数据的：分析数据、调整数据、读取和存储数据、生成数据等。深度学习领域也不例外。图像、权重/过滤器、声音和文本需要在计算机内存中有效表示，以便以最方便的方式快速执行操作。

本节专门讨论数据格式一种数据表示形式，它描述了多维数组 (nD) 如何存储在线性 (1D) 内存地址空间中，以及为什么这对深度学习很重要。

### 数据格式
让我们首先关注激活（图像）的数据格式。

激活由通道（也称为特征图）和空间域、1D、2D 或 3D 组成。空间域与通道一起形成一个图像。在训练阶段，图像通常分批组合在一起。即使只有一张图像，我们仍然假设有一个批大小等于 1 的批。因此，激活的总维数是 4D（N、C、H 和 W）或 5D（N、C、D 、H 和 W)。

### plain data formats

从一个例子开始会更简单。

考虑批处理等于2,16个通道和 5 x 4 空间域的4D特征图像。下图给出了示意表达。
![表达式图像](https://oneapi-src.github.io/oneDNN/_images/mem_fmt_img1.png)

位置 (n, c, h, w) 处的值由以下公式生成
```
value(n,c,h,w) = n*CHW + c*HW + h*W + w
```
为了定义这个 4D 张量中的数据如何在内存中布局，我们需要定义如何通过一个以逻辑索引 (n, c, h, w) 作为输入的偏移函数将其映射到一个 1D 张量.
```
offset:(int,int,int,int) ---> int
```
#### nchw
在BVLC*Caffe中默认使用

#### NHWC
```
offset_nhwc(n,c,h,w) = n *HWC + h * WC + w*C + c
```
NHWC数据格式是Tensorflow的默认格式

#### CHWN
```
offset_chwn(n,c,h,w) = c * HWN + h * WN + w * N + n
```
![数据排布](https://oneapi-src.github.io/oneDNN/_images/mem_fmt_img2.png)

----
使用rgb图转换为灰度图来说明 datalayout对数据的计算的影响
其中rgb图有使用已下两种格式来排布
![rgb通道数](/images/posts/2021-11-04-数据layou的应用08.png)

对于第一种排布，即RRRRRGGGGGGGGGGGGGGBBBBBB这样格式，如下所示，计算灰度的过程如下
![dd](/images/posts/2021-11-04-数据layou的应用09.png)

对于第二种排布，即rgbrgbrgbrgbrgb这样格式，如下所示，计算灰度的过程如下：
![dd](/images/posts/2021-11-04-数据layou的应用11.png)

从图中可以看出，两种进行rgb-->灰度计算的复杂度是相同的，区别在于访存特性。**从图可以看出，NHWC的访存区域性更好（每三个输入元素就可以得到一个元素，而HCHW则必须等待所有通道输入准备好后，才能得到最终输出结果，需要占用较大的临时空间）**
> tensorflow为什么选择nhwc作为预定格式，因为早期开发都是基于cpu,使用nhwc比nchw快一些，因为nhwc区域性更好，cache利用率高

> nchw则是nvidia cudnn的预定格式，使用gpu加速使用nchw格式数据更快。






#### blocked layout
简单的布局提供了很大的灵活性，使用起来非常方便。这就是为什么大多数框架和应用程序使用 NCHW 或 NHWC 布局的原因。但是，根据对数据执行的操作，从性能角度来看，这些布局可能不是最佳的。

```
offset_nChw8c(n,c,h,w) = n * CHW 
                       + (c/8) * HW*8
                       + h * W * 8
                       + w * 8
                       + (c % 8)
```
![分块数据](https://oneapi-src.github.io/oneDNN/_images/mem_fmt_blk.png)
分块数据布局为卷积提供了显着的性能提升，但是当通道数不是块大小的倍数时（例如，nChw8c 格式为 17 个通道）怎么办？**padding**
