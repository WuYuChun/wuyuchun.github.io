# 生成式深度学习

有关创造力的终极问题：**能否创造出本身具有创造力的东西？**

> 《hands-on Machine Learning with Scikeit-learn,keras,and Tensorflow:Concenpt,Toolsand Techniques to Build Intelligent System》
>
> 《Deep leaning whith python》

https://paperswithcode.com/  ：各种机器学习任务的最新技术成果

> 本书代码：https://github.com/davidADSP/GDL_code  



# 生成式深度学习概述

从概率的角度思考我们设法解决生成建模领域

 

## 生成建模



### 什么是生成建模

定义：**生成模型从概率模型的角度描述了生成数据集的方法。从该模型中抽样即可生成新数据**

![](/images/posts/生成式深度学习-01.jpg)

生成模型必须是概率的，不能是确定的，因为若是咱们的模型只是一个固定的计算，就不能称之为生成式，因为这种模型每次都会产生相同的输出。

训练数据集中存在某种未知的概率分布。

判别模型和生成模型的区别：

- 判别模型是一个带有标签的数据集将输入映射成输出的函数
- 生成模型通常会使用没有标签的数据集来执行

生成模型是解锁强人工智能的方式：

- 更全面了解数据最初的生成方式
- 驱动机器学习其他领域未来发展的关键：例如让车辆在想象中的环境进行学习
- 生成建模必然在强智能方面占一席之地

```
生成建模框架
1.有观测X的数据集
2.假设这些观测是根据某一个未知的分布P生成的
3.生成模型P1试图模仿P,如果我们能实现这个目标，则可以从P1采样并观测，且生成的观测看上去就好像是从P提取的结果
4.如果满足以下条件，则代表P1建模成功
	4.1该模型生成的采样看上去好像是从P提取的结果
	4.2该模型生成的采样与X中的观测明显不同
```





### 概率生成建模

- 样本空间
- 概率密度函数
- 参数化建模
- 似然函数：找最合理的参数值a,以最大化数据集X观测值的似然性。（最大似然估计）



### 生成建模的难题

- 朴素贝叶模型是独立采样像素，因此无法得知两个相邻像素的颜色是否非常相似。
- 样本空间中的可观测数量十分庞大，模型难以理解

```
生成模型的难题
1.模型如何处理特征之间的高度条件依赖？
2.模型如何在高纬样本空间中，找到令人满意的一小部分数据？
```

表示学习的核心思想：不要尝试直接对高纬样本空间建模，而是通过一些低纬空间来描述训练集中的每一个观测，然后学习一个映射函数，将隐空间中的点映射到原始域中。

从数学的角度来讲，它会设法找出数据表现出的高度非线性流形，然后建立充分描述该空间所需的维度

```shell
git clone https://github.com/davidADSP/GDL_code.git
git pull
```

设置一个虚拟环境

```shell
#如果使用Anaconda
coda create -n generative python=3.6 ipykernel
#如果没有Anaconda，可以按照virtualenv和virtualenwrapper
pip install virtualenv virtualenvwrapper
export WORKON_HOME=$HOME/.virtualenvs  #虚拟环境存储的位置
export VIRTUALENVWRAPPER_PYTHON=/usr/local/bin/python3 #初始化虚拟环境使用的python
source /usr/local/bin/virtualenvwrapper.sh  #重新加载虚拟环境的初始化脚本
```

```shell
pip install -r requirement.txr
```

```shell
#测试环境
>>> import keras
Using TensorFlow backend
>>> keras.__Verison__
'2.2.4'
```



```shell
#使用jupyter notebook
#在虚拟终端在执行环境
python -m ipykernel install --user --name generative
#在终端进入保持代码的文件夹
jupyter notebook
```



## 深度学习

> 深度学习是一类机器学习算法，使用多个堆叠层的处理单元来学习非结构化数据的高层表征



### 结构与非结构数据

结构数据：表等

非结构数据：图像、语音、视频





### 深度神经网络

> kerals 和tensorflow

```python
model.summary()#查看神经网络的形状
```



### 改进模型

协变量偏移：？===》批标准化



## 变分自动编码器

> 画展的故事--》A 用点表示画，B通过点推测画

### 自动编码器

自动编码器包含两个部分：

- 将高纬输入数据压缩成低纬表征向量的编码器神经网络
- 通过解压将给定的表征向量还原到原始域的解码器神经网络

自动编码器存在的问题：

- 选择一个随机的点本事没有明显的意义，因为这些点的分布是没有定义
- 自动编码器无法保证获得大致相等的数字分布
- 各个点之间缝隙太大

### 构建变分自动编码器

在自动编码器重，每个图像都直接映射成隐空间中的一点，而在变分自动编码中，每一个图像都映射成隐空间中围绕某一个点的多元正太分布。

![](/images/posts/生成式深度学习-02.jpg)







## 生成对抗网络



### 第一个生成对抗网络



### GAN面临的难题



### WGAN



### WGAN-GP





